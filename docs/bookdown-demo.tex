\documentclass[]{book}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdftitle={Basic Stats},
            pdfauthor={Bill Last Updated:},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{natbib}
\bibliographystyle{apalike}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\providecommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}

  \title{Basic Stats}
    \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
    \author{Bill Last Updated:}
    \preauthor{\centering\large\emph}
  \postauthor{\par}
      \predate{\centering\large\emph}
  \postdate{\par}
    \date{25 April, 2020}

\usepackage{booktabs}
\usepackage{amsthm}
\makeatletter
\def\thm@space@setup{%
  \thm@preskip=8pt plus 2pt minus 4pt
  \thm@postskip=\thm@preskip
}
\makeatother

\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{my-section}{%
\chapter*{Preface: Motivation}\label{my-section}}
\addcontentsline{toc}{chapter}{Preface: Motivation}

All the notes I have done here are about basic stats. While I have tried my best, probably there are still some typos and errors. Please feel free to let me know in case you find one. Thank you!

\hypertarget{section}{%
\chapter{443}\label{section}}

\hypertarget{some-basic-concepts}{%
\section{Some basic concepts}\label{some-basic-concepts}}

\hypertarget{random-variable}{%
\subsection{Random variable}\label{random-variable}}

Any numerical realization of a random experiment results in a random variable.

In layman terms, it is a number that has a certain probability attached to it.

\hypertarget{permutation}{%
\subsection{Permutation}\label{permutation}}

An ordered arrangement of a set of objects is known as a permutation.

e.g., The number of permutations of n distinguishable objects is \(n!\).
e.g., The number of permuations of n distinct objects taken r at a time is

\[_{n}P_r=\frac{n!}{(n-r)!}\]

\hypertarget{combinations}{%
\subsection{Combinations}\label{combinations}}

If the order of the objects is not important, then one may simply be interested in the number of combinations.

\[\binom{n}{r}=\frac{n!}{r!(n-r)!}\]

\hypertarget{partitioning}{%
\subsection{Partitioning}\label{partitioning}}

The number of ways of partitioning a set of n objects into k cells with \(r_1\) objects into the first cell, \(r_2\) in the second cell, and so forth is

\[\frac{n!}{r_1! r_2! ...r_k!}\]

\hypertarget{discrete-random-variables}{%
\section{Discrete Random Variables}\label{discrete-random-variables}}

\hypertarget{binomial}{%
\subsection{Binomial}\label{binomial}}

\[X\sim BIN(n,p)\]

\[\binom{n}{x}P^x(1-P)^{n-x}\]
mean: \(np\)

variance: \(npq\)

Support (or, possible values): \(0, 1, 2,...n\)

(Note that, Bernoulli is written as \(BIN(1, p)\))

\hypertarget{poisson}{%
\subsection{Poisson}\label{poisson}}

\[X \sim POI(\mu)\]
\[\frac{e^{-\mu}\mu^x}{x!}\]
mean: \(\mu\)

variance: \(\mu\)

Support (or, possible values): \(0, 1, 2,...\) (i.e., 0+ positive integer; or Natural number)

\hypertarget{continuous-random-variables}{%
\section{Continuous Random Variables}\label{continuous-random-variables}}

\hypertarget{uniform}{%
\subsection{Uniform}\label{uniform}}

\[X \sim UNIF(a,b)\]

\[\frac{1}{b-a}\]

Mean: \(\frac{a+b}{2}\)

Variance: \(\frac{(b-a)^2}{12}\)

Support (or, possible values): \(a<x<b\)

\hypertarget{exponential}{%
\subsection{Exponential}\label{exponential}}

\[X \sim EXP(\theta)\]

\[\frac{1}{\theta} e^{-x/\theta}\]
Mean: \(\theta\)

Variance: \(\theta^2\)

Support (or, possible values): \(0<x\)

\hypertarget{normal}{%
\subsection{Normal}\label{normal}}

\[X\sim N(\mu, \sigma^2)\]

\[\frac{1}{\sqrt{2 \pi \sigma}} e^{-\frac{1}{2}(\frac{x-\mu}{\sigma})^2}\]

Mean: \(\mu\)

Variance" \(\sigma^2\)

Support (or, possible values): \(-\infty<x<+\infty\)

\hypertarget{large-sample-theory}{%
\section{Large Sample Theory}\label{large-sample-theory}}

\hypertarget{convergence-in-distribution}{%
\subsection{Convergence in distribution}\label{convergence-in-distribution}}

\url{https://en.wikipedia.org/wiki/Law_of_large_numbers}

\[\bar{X} \rightarrow \mu \; \; \; (n \rightarrow \infty)\]

\[Var(\bar{X})=Var(\frac{1}{n}(X_1+...+X_n))=\frac{1}{n^2}Var(X_1+...+X_n)=\frac{n \sigma^2}{n^2}=\frac{\sigma^2}{n}\]

\hypertarget{weak-law}{%
\subsection{Weak law}\label{weak-law}}

There are two different versions of the Law of Large Numbers: Strong law of large numbers and Weak law of large numbers.

The weak law of large numbers: The sample average converges \textbf{in probability} towards the expected value.

\[\bar{X_n} \xrightarrow{p} \mu \; \; \; (n \rightarrow \infty)\]
This, for any positive number \(\epsilon\)

\[lim_{n \rightarrow \infty} Pr(|\bar{X_n}-\mu|>\epsilon)=0\]

\hypertarget{strong-law}{%
\subsection{Strong law}\label{strong-law}}

\url{http://maxim.ece.illinois.edu/teaching/fall12/handouts/LLN.pdf}

The sequence of sample mean \(\bar{X}_n\) converges to \(\mu\) \textbf{almost surely}.

\[\bar{X_n} \xrightarrow{a.s.} \mu \; \; \; (n \rightarrow \infty)\]
This is,

\[Pr(lim_{n \rightarrow \infty} \bar{X_n}=\mu)=1\]

\hypertarget{central-limit-theorem}{%
\subsection{Central limit theorem}\label{central-limit-theorem}}

If \(X_1,...,X_n\) is a random sample from a distribution with mean \(\mu\) and variance \(\sigma^2 < \infty\), then the limiting distribution of

\[Z_n=\frac{\sum_{i=1}^n X_i - n\mu}{\sqrt{n} \sigma}\]

is the standard normal, \(Z_n \xrightarrow{d} Z \sim N(0,1)\) as \(n \rightarrow \infty\).

\hypertarget{bernoulli-law-of-large-number}{%
\subsubsection{Bernoulli law of large number}\label{bernoulli-law-of-large-number}}

\(\hat{p}_n=\frac{Y_n}{n}\) converges stochasticalltly to \(p\) as \(n\) approchaes infinity. For example, if a coin is tossed repeatedly, and \(A=\{H\}\), then the successive relative frequencies of A correspond to a sequence of random variables that will converge stochastically to \(p=1/2\).

\hypertarget{normal-approximation-to-binomial}{%
\subsubsection{Normal approximation to Binomial}\label{normal-approximation-to-binomial}}

\[Z_n=\frac{Y_n-np}{\sqrt{npq}} \xrightarrow{d} Z \sim N(0, 1)\]

Example: The probability that a basketball player hits a shot is \(p=0.5\). If he takes 20 shorts, what is the probability that he hits at least 9?

\[\begin{aligned} P[Y_{20} \geq 9] &=1-P[Y_{20} < 8] \\ &=1- \sum_{y-0}^8 \binom{20}{y} 0.5^y0.5^{20-y} \\&=0.7483 \end{aligned} \]

A normal approximation is

\[\begin{aligned} P[Y_{20} \geq 9] &=1-P[Y_{20}<8] \\ &=1- \Phi(\frac{8-10}{\sqrt{5}}) \\&=0.8133 \end{aligned} \]

\hypertarget{normal-approximation-to-poisson}{%
\subsubsection{Normal approximation to Poisson}\label{normal-approximation-to-poisson}}

\[\begin{aligned} P[10\leq Y_{20} \leq 30] &=P[ Y_{20} \leq 30]-P[ Y_{20} \leq 10] \\&=\Phi[\frac{30.5-20}{\sqrt{20}}]-\Phi[\frac{9.5-20}{\sqrt{20}}] \\ &=0.981 \end{aligned}\]

\hypertarget{poisson-approximation-to-binomial}{%
\subsection{Poisson approximation to binomial}\label{poisson-approximation-to-binomial}}

We know that the mean for binomial is

\[\mu=np \rightarrow p=\frac{\mu}{n}\]
The moment generating function for Binomial is

\[M_n(t)=(1-p+pe^t)^n=(1+\frac{\mu (e^t-1)}{n})^n\]
\[lim_{n \rightarrow \infty} M_n(t)=e^{\mu (e^t-1)}\]

Note that the MGF for Poisson is as follows.

\[POI(\lambda): e^{\lambda(e^t-1)}\]

Thus,

\[Y_n \rightarrow Y \sim POI (\mu)\]

\hypertarget{section-1}{%
\chapter{556}\label{section-1}}

\hypertarget{statistics-and-sampling-distributions}{%
\section{Statistics and Sampling Distributions}\label{statistics-and-sampling-distributions}}

\hypertarget{statistics}{%
\subsection{Statistics}\label{statistics}}

\hypertarget{definition-of-statistic}{%
\subsubsection{Definition of Statistic}\label{definition-of-statistic}}

\emph{P.264}

A fucntion of observable random variables, \(T=t(X_1, ... X_n)\), which does not depend on any unknown parameters is called statistic.

For example, let \(X_1, ..., X_n\) represent a random sample from a population with \(pdf \;f(x)\). The sample mean provides an example of a statistic with the function

\[t(x_1,...,x_n)=(x_1+...+x_n)/n\]

This statistic usually is denoted by

\[\bar{X}=\sum_{i=1}^n \frac{X_i}{n}\]

When a random sample is observed, the value of \(\bar{X}\), computed from the data, usually is denoted by lower case \(\bar{x}\).

\[\bar{x}=\sum_{i=1}^n \frac{x_i}{n}\]

\hypertarget{sample-and-parameters}{%
\subsubsection{Sample and parameters}\label{sample-and-parameters}}

\emph{P.265}

If \(X_1,..., X_n\) denotes a random sample from \(f(x)\) with \(E(X)=\mu\) and \(var(X)=\sigma^2\), then

\[E(\bar{X})=\mu\]

\[Var(\bar{X})=\frac{\sigma^2}{n}\]

\textbf{Example:}

A random sample of size \(n\) from a Bernoulli distribution \(X_i \sim BIN(1,p)\). We know Bernoulli has \(\mu=p\) and \(\sigma^2 =pq\). In this case, the sample mean is

\[\bar{X}=Y/n=\hat{p}\]

Thus,

\[E(\hat{p})=p\]

\[Var (\hat{p})=\frac{pq}{n}\]

Thus, sample mean is the unbiased estimate for the population mean. However, the variance of the mean is not equal to population variance. That lead to definition of sample variance.

\emph{P.266}

Sample variance:

\[S^2=\frac{1}{n-1}\sum_{i=1}^n(X_i-\bar{X})^2\]

\[E(S^2)=\sigma^2\]

(Question: does it mean that sample varaince is an unbiased estimator of population variance?)

\hypertarget{chi2-t-f-beta}{%
\subsection{\texorpdfstring{\(\chi^2, t, F, beta\)}{\textbackslash chi\^{}2, t, F, beta}}\label{chi2-t-f-beta}}

\hypertarget{chi2}{%
\subsubsection{\texorpdfstring{\(\chi^2\)}{\textbackslash chi\^{}2}}\label{chi2}}

\emph{P.271}

If \(X_1,...,X_n\) denotes a random sample from \(N(\mu,\sigma^2)\), then

\[\sum_{i=1}^n \frac{(X_i-\mu)^2}{\sigma^2} \sim x^2(n)\]
\[\frac{n(\bar{X}-\mu)^2}{\sigma^2}\sim x^2(1)\]

\[\frac{(n-1)S_n^2}{\sigma^2} \sim \chi^2(n-1)\]
(Thus, we can see this is a bit weired, as the numerator is \(\bar{X}\) is from the sample, whereas \(\sigma^2\) is from the population. Thus, assume we know \(\sigma^2\)?)

Thus, we can

\[\frac{\sum_{i=1}^n(X_i-\bar{X})^2}{\sigma^2}\sim \chi^2(n-1)\]
(You can compare \(\bar{X}\) with \(\mu\), we can see the only difference is that the \(\chi^2\) has one less degree of freedom because we use this degree of freedom to calculate the mean.)

For the mean and variance of \(\chi^2\):

Assume that

\[X \sim x^2(v)\]

\[mean:v\]
\[variance: 2v\]

\hypertarget{t}{%
\subsubsection{\texorpdfstring{\(t\)}{t}}\label{t}}

Definition

\[t(k)=\frac{N(0,1)}{\sqrt{\frac{\chi^2(k)}{k}}}\]

\textbf{Property 1}

\emph{t} distribution is symmetrical.

Given that \emph{t} distribution is symmetrical, we can get

\[H(-c)=1-H(c)\]

\textbf{Property 2}

\emph{t} distribution has heavier tails than the normal.

My note: \emph{t} distribution only has a parameter of \(k\), which is determined by the \(\chi^2\)'s degree of freedom. Of course, \(\chi^2\) also only has one parameter, namely the degree of freedom.

\hypertarget{f}{%
\subsubsection{\texorpdfstring{\(F\)}{F}}\label{f}}

If \(V_1 \sim \chi^2(v_1)\) and \(V_2 \sim \chi^2(v_2)\) are independent, then the random variable

\[\frac{V_1/v_1}{V_2/v_2}\sim F(v_1,v_2)\]

\hypertarget{beta}{%
\subsubsection{Beta}\label{beta}}

If \(X \sim F(v_1, v_2)\)

\[Y=\frac{(v_1/v_2)X}{1+(v_1/v_2)X} \sim Beta(\alpha, \beta)\]

\hypertarget{large-sample-approximations}{%
\subsection{Large-sample approximations}\label{large-sample-approximations}}

\emph{P.280}

If \(Y_v \sim x^2(x)\), then

\[Z_v =\frac{Y_v-v}{\sqrt{2v}} \xrightarrow{d} Z \sim N(0,1)\]

(The proof is based on CLT. In addition, as disscused above, we can get chi-square from normal distributions.)

\hypertarget{point-estimation}{%
\section{Point Estimation}\label{point-estimation}}

\hypertarget{method-of-moments-estimators}{%
\subsection{Method of moments estimators}\label{method-of-moments-estimators}}

\hypertarget{definition-about-moments-chapter-2}{%
\subsubsection{Definition about moments (chapter 2)}\label{definition-about-moments-chapter-2}}

\emph{P.73}

THe \textbf{kth moment about the origin} of a random variable \(X\) is

\[\mu^{'}_k=E(X^k)\]

and the \textbf{kth moment about the mean} is

\[\mu_k=E[X-E(X)]^k=E(X-\mu)^k\]

Thus,\(k=E(X^k)\) may be considered as the \(k\)th moment of \(X\) or the first moment of \(X^k\).

The first moment about the mean is zero,

\[\mu_1=E[X-E(X)]=E(X)-E(X)=0\]

The second moment about the mean is the variance,

\[\mu_2=E[(X-\mu)^2]=\sigma^2\]

Note that the definition of variance:

\emph{P.73}

\[Var(X)=E[(X-\mu)^2]\]

( \textbf{Note: Based on the information above, it seems important to understand the difference between the moment of the origin and the moment of the mean.} )

\hypertarget{definition}{%
\subsubsection{Definition}\label{definition}}

Based on the last chapater (i.e., Chapter 8), sample mean \(\bar{X}\) is an estimator of the population mean \(\mu\). A more general approach, which produced estimators known as the \textbf{method of moments estimators(MMEs)} , can be developed.

If \(X_1,...,X_n\) is a random sample from \(f(x; \theta_1,...,\theta_k)\), the first \(k\) sample moments are given by

\[M_j^{'}=\frac{\sum_{i=1}^n X_i^j}{n}\]

where,

\[j=1,2,...k\]

\textbf{Example 1:}

\emph{P.291}

Consider a random sample from a distribution with two unknown parameters, the mean \(\mu\) and the variance \(\sigma^2\). We know from earlier considerations that \(\mu=\mu^{'}_1\) and \(\sigma^2=E(X^2)-\mu^2=\mu_2^{'}-(\mu^{'}_1)^2\).

Thus,

\[\hat{\sigma}^2=\mu_2^{'}-(\mu^{'}_1)^2=\frac{\sum_{i=1}^n X_i^2}{n}-\bar{X}^2=\sum_{i=1}^n \frac{(X_i-\bar{X})^2}{n}\]

(Thus, we can see that the MME estimation of \(\sigma^2\) is not the same as the definition of sample variance \(S^2\). \(\hat{\sigma}^2=\frac{n-1}{n}S^2\). So, the MME estimator is not an unbiased one?)

\textbf{Example 2:}

\emph{P.292}

If a sample is from a Gamma distribution \(X_i \sim GAM(\theta,k)\), and we want to estimate the \(\theta\) and \(k\).

We know that for Gamma distribution, the mean is \(k\theta\), and the variance is \(k\theta^2\).

We also know that

\[\mu_1^{'}=\mu=k\theta\]

and

\[\mu_2^{'}= \sigma^2+\mu^2= k\theta^2+k^2\theta^2=k\theta^2(1+k)\].

Thus, we can get

\[\bar{X}=k\theta\]

\[\sum \frac{X_i^2}{n}=k\theta^2(1+k)\]

Thus, we can get

\[\hat{\theta}=\sum_{i=1}^n \frac{(X_i-\bar{X})^2}{n \bar{X}}=\frac{(n-1)/n S^2}{\bar{X}}\]

\[\hat{k}=\frac{\bar{X}}{\hat{\theta}}\]

( \textbf{Note: To sum up, (1) we know how to calculate moments based on sample. And, (2) we know that connection between moment and parameter of mean and variance. Thus, combining (1) and (2), we can get the estimators for the parameters.} )

\hypertarget{property}{%
\subsubsection{Property}\label{property}}

The joint MGF of (\(X_1, ..., X_n\)) is defined as \(M(t_1,...,t_n)=E(e^{\sum_{i=1}^nt_iX_i})\)

When \(X_1, ..., X_n\) are independent if and only if

\[M(t_1,...,t_n)=\prod_{i=1}^n M_{X_i}(t_i)\]
where \(M_{X_i}(t_i)\) is the MGF of \(X_i\)

\hypertarget{well-known-mgf}{%
\subsubsection{Well-known MGF}\label{well-known-mgf}}

\begin{enumerate}
\def\labelenumi{(\arabic{enumi})}
\item
  Bernoulli with success probability \(p\): \(1-p+pe^t\)
\item
  Binomial \(Bin(n,p)\): \((1-p+pe^t)^n\)
\item
  Poisson \(POI(\lambda)\): \(e^{\lambda(e^t-1)}\)
\item
  Normal \(N(\mu,\sigma^2)\): \(e^{\mu t+\frac{1}{2}\sigma^2t^2}\)
\item
  Gamma \(GAM(\theta,k)\): \((1-\theta t)^{-k}\)
\end{enumerate}

\textbf{Two special cases:}

\begin{enumerate}
\def\labelenumi{(\arabic{enumi})}
\setcounter{enumi}{5}
\item
  Chi-square \(\chi^2(v) =GAM(2,\frac{v}{2})\): \((1-2t)^{-\frac{v}{2}}\)
\item
  Exponential \(EXP(\theta)=GAM(\theta,1)\): \((1-\theta t)^{-1}\)
\end{enumerate}

\hypertarget{least-squares-estimators}{%
\subsection{least squares estimators}\label{least-squares-estimators}}

\hypertarget{likelihood-function-and-maximum-likelihood-estimators}{%
\subsection{likelihood function and maximum likelihood estimators}\label{likelihood-function-and-maximum-likelihood-estimators}}

\hypertarget{likelihood-function}{%
\subsubsection{Likelihood function}\label{likelihood-function}}

\emph{P.293}

The joint density function of \(n\) random variables \(X_1,...X_n\) evaluated at \(x_1, ...x_n\), say \(f(x_1,...,x_n; \theta)\), is referered to as a \emph{likelihood function}.

\hypertarget{maximum-likelihood-estimators}{%
\subsubsection{Maximum likelihood estimators}\label{maximum-likelihood-estimators}}

\emph{P.294}

Let \(L(\theta)=f(x_1,...x_n; \theta), \theta \in \Omega\), be the joint pdf of \(X_1, ..., X_n\). For a given set of observations, \((x_1,...x_n)\), a value \(\hat{\theta}\) in \(\Omega\) at which \(L(\theta)\) is a maximum is called a \emph{maximum likelihood estimate (MLE)} of \(\theta\). That is \(\hat{\theta}\) is a value of \(\theta\) that satisfies

\[f(x_1,...x_n; \theta)=MAX_{\theta \in \Omega} f(x_1, ..., x_n; \theta)\]

\hypertarget{invariance-property-of-mles}{%
\subsection{Invariance property of MLEs}\label{invariance-property-of-mles}}

\emph{P.296}

If \(\hat{\theta}\) is the MLE of \(\theta\) and if \(u(\theta)\) is a function of \(\theta\), then \(u(\hat{\theta})\) is an MLE of \(u(\theta)\).

\textbf{Example 1:}

We know that the \(pdf\) of exponential distribution (\(X \sim EXP (\theta)\)) is as follows:

\[\frac{1}{\theta} e^{-\frac{X}{\theta}}\]

Thus, its likelihood function is as follows

\[L(\theta)=\frac{1}{\theta^n}e^{-\frac{\sum X_i}{\theta}}\]
Thus, log-likelihood is as follows.

\[lnL(\theta)=-n ln(\theta)-\frac{\sum X_i}{\theta}\]
Thus,

\[\frac{d}{d\theta} lnL(\theta)=-n \frac{1}{\theta}+\frac{\sum X_i}{\theta^2}\]

Thus, we can get the \(MLE\) for \(\theta\) is \(\hat{\theta}=\bar{x}\).

If we want to estimate \(\tau(\theta)=P(X \geq 1)\):

\[\tau(\theta)=P(X\geq 1)=\int_1^{\infty} \frac{1}{\theta} e^{-\frac{X}{\theta}} dx=-\int_1^{\infty}  e^{-\frac{X}{\theta}} d(-\frac{x}{\theta})=-[e^{-\frac{X}{\theta}}]_1^{\infty}=-[0-e^{-\frac{1}{\theta}}]=e^{-\frac{1}{\theta}}\]

Thus, based on the invariance property, we know that the \(MLE\) for \(\tau(\theta)\) is as follows.

\[e^{-\frac{1}{\bar{x}}}\]

\textbf{Example 2: MLE vs.~MME}

\emph{P.296}

Assume a random sample from a two-parameter exponential distribution, \(X_i \sim EXP(1,\eta)\). Thus, the \(pdf\) is \(e^{-(x-\eta)}\). Thus, the likelihood function is

\[L(\eta)=e^{-\sum(x_i-\eta)}\]

Thus, the log likelihood,

\[lnL(\eta)=-\sum(x_i-\eta)=n\eta-n\bar{X}\]
Thus, we know that as \(\eta\) increases, the log likelihood increases accordingly. Thus, we want to find the maximum \(\eta\). Note that a two-parameter exponential distribution has the support of \(x_i \geq \eta\). Thus, all \(\eta\) are smaller than any \(X_i\). Thus, we can get the ML estimator is the first order statistic

\[\hat{\eta}=X_{1:n}\]

\textbf{Note that} the estimators above is based on ML. What would be the answer if using MME?

We know that for a two-parameter exponential distribution, its mean is \(\mu=1+\eta\). And, we know that based on MME, \(\mu=\bar{X}\). Thus, we can get the following,

\[\hat{\eta}=\bar{X}-1\]

\textbf{Conclusion}

We can see that ML and MME have didferent estimators for the same \(\eta\) for a two-parameter exponential distribution.

\hypertarget{unbiased-estimators}{%
\subsection{Unbiased estimators}\label{unbiased-estimators}}

An estimator \(T\) is said to be an unbiased estimator of \(\tau(\theta)\) if

\[E(T)=\tau(\theta)\]

for all \(\theta \in \Omega\). Otherwise, we said that \(T\) is biased stimator of \(\tau(\theta)\).

For instance, if we want to estimate a percentile, say the 95th percentile of \(N(\mu,9)\). Note that the percentiles that we know are about standardized noraml (i.e., \(N(0,1)\)). Thus, we need to have some calculation to get the non-standard one.

\[\frac{X_{95 \; percentile}-\mu}{\sigma}=1.645\]
Thus, we can get

\[X_{95 \; percentile}=1.645 \times \sigma +\mu\]

We know that \(\bar{X}\) is the unbiased estimate for \(\mu\). Thus, we can get

\[X_{95 \; percentile}=1.645 \times \sigma +\mu=4.94+\mu\]

We know that

\[E(T)=E(\bar{X}+4.94)=\mu+4.94\]
Thus, \(T=\bar{X}+4.94\) is the unbiased estimator of \(\tau(\mu)=\mu+4.94\).

\hypertarget{unbiased-estimators-vs.-invariance-property-of-mles}{%
\subsection{Unbiased estimators vs.~Invariance property of MLEs}\label{unbiased-estimators-vs.-invariance-property-of-mles}}

\textbf{Do not apply ``Invariance property of MLEs'' to the Unbiased estimators.}

( \textbf{Note that:} You can apply the Invariance property to ``Unbiased estimators'' when it is a linear combination. In that case, \(E(a\theta+b)=aE(\theta)+b\). Thus, if you find a \(T\) that is a unbiased estimator for \(\theta\), it should be unbiased estimator for \(a\theta+b\) as well. Thus, note that \(\frac{1}{\theta}\) is not a linear combination of \(\theta\), thus \(\frac{1}{\theta}\) has a very different estimator, compared to \(\theta\).)

\emph{P.303}

For example, consider a random sample of size \(n\) from an exponential distribution, \(X_i \sim EXP(\theta)\), with parameter \(\theta\). We know that, \(\bar{X}\) is unbiased for \(\theta\) (which is the mean of an exponential distribution).

If we want to estimate \(\tau(\theta)=\frac{1}{\theta}\), then by the invariance property of MLE is \(T_1=\frac{1}{\bar{X}}\).

However, \(T_1\) is a biased estimators of \(\frac{1}{\theta}\). Specifically,

We know that if \(X \sim Gam(\theta,k)\), then \(Y=\frac{2X}{\theta} \sim x^2(2k)\). We know that exponential distributions are a specicial case of Gamma distribution, \(EXP(\theta)=Gam(\theta,1)\), thus we get the following,

\[Y=\frac{2n\bar{X}}{\theta}=\frac{2n}{\theta} \frac{\sum_{i=1}^n X_i}{n}=\frac{\sum_{i=1}^n 2X_i}{\theta}\sim\sum_{i=1}^n x^2(2\cdot1)=\sum_{i=1}^n x^2(2)=x^2(2n)\]

We further know that if \(Y \sim x^2(v)\), \(E(Y^r)=2^r\frac{\Gamma(v/2+r)}{\Gamma(v/2)}\). Thus, we know that,

\[E(Y^{-1})=2^{-1} \frac{\Gamma(2n/2-1)}{\Gamma(2n/2)}=\frac{1}{2}\cdot \frac{1}{n-1}\]

Thus,

\[E(Y^{-1})=E(\frac{\theta}{2n \bar{X}})=\frac{\theta}{2n}E(\frac{1}{\bar{X}})=\frac{1}{2}\cdot \frac{1}{n-1}\]

Thus.

\[E(\frac{1}{\bar{X}})=\frac{1}{n-1}\frac{n}{\theta}=\frac{n}{n-1}\frac{1}{\theta}\]

Thus,

\[E(\frac{n-1}{n} \frac{1}{\bar{X}})=\frac{1}{\theta}\]

\textbf{Conclusion:}

\(\frac{1}{\bar{X}}\) is not the unbiased estimator for \(\frac{1}{\theta}\). However, we can adjust it to \(\frac{n-1}{n} \frac{1}{\bar{X}}\), which is the unbiased estimator for \(\frac{1}{\theta}\). When the sample size is big enough, we know that \(\frac{n-1}{n}\) will be close to 1.

\hypertarget{umvue-and-cramer-rao-lower-bound}{%
\subsection{UMVUE and Cramer-Rao lower bound}\label{umvue-and-cramer-rao-lower-bound}}

\hypertarget{umvue}{%
\subsubsection{UMVUE}\label{umvue}}

Let \(X_1, X_2,...,X_n\) be a random sample of size \(n\) from \(f(x; \theta)\). An estimator \(T^*\) of \(\tau (\theta)\) is called a \emph{uniformly minimum variance ubiased estimator} (UMVUE) of \(\tau(\theta)\) if

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \(T^*\) is unbiased for \(\tau (\theta)\).
\item
  For any other unbiased estimator \(T\) of \(\tau(\theta)\), \(Var(T^*) \leq Var(T)\) for all \(\theta \in \Omega\).
\end{enumerate}

\hypertarget{cramer-rao-lower-bound}{%
\subsubsection{Cramer-Rao lower bound}\label{cramer-rao-lower-bound}}

If \(T\) is an unbiased estimator of \(\tau(\theta)\), then the Cramer-Rao lower bound (CRLB), based on a random sample, is

\[Var(T)=\frac{[\tau^{'}(\theta)]^2}{nE[\frac{\partial}{\partial \theta} ln f(X; \theta)]^2}\]

\textbf{Example:}

Consider a random sample from an exponential distribution, \(X_i \sim Exp(\theta)\). Because

\[f(x; \theta)=\frac{1}{\theta} e^{-\frac{x}{\theta}}\]

Thus,

\[ln(f(x;\theta))=-\frac{x}{\theta}-ln \theta\]

\[\frac{\partial}{\partial \theta} ln(f(X; \theta))=\frac{X}{\theta^2}-\frac{1}{\theta}=\frac{X-\theta}{\theta^2}\]

Thus,

\[E[\frac{\partial}{\partial \theta} ln(f(X; \theta))]^2 =E[\frac{(X-\theta)^2}{\theta^4}]=\frac{1}{\theta^4}E(X-\theta)^2=\frac{1}{\theta^4} Var(X)=\frac{\theta^2}{\theta^4}=\frac{1}{\theta^2}\]

Thus, the CRLB for \(\tau(\theta)=\theta\) is as follows.

\[Var(T) \geq \frac{[\tau^{'}(\theta)]^2}{nE[\frac{\partial}{\partial \theta} ln f(X; \theta)]^2}=\frac{[\frac{\partial }{\partial \theta}\theta]^2}{n \frac{1}{\theta^2}}=\frac{1^2}{\frac{n}{\theta^2}}=\frac{\theta^2}{n}\]

We know that the variance for the sample mean of the exponential distribution:

\[Var(\bar{X})=\frac{Var(X)}{n}=\frac{\theta^2}{n}\]

In addition, we also know that sample mean \(\bar{X}\) is the unbiased estimator for population mean.

Thus,

\(\bar{X}\) is the UMVUE of \(\theta\).

\hypertarget{best-linear-unbiased-estimation-blue-or-mvlue}{%
\subsection{Best linear unbiased estimation (BLUE or MVLUE)}\label{best-linear-unbiased-estimation-blue-or-mvlue}}

\url{https://statisticsbyjim.com/regression/gauss-markov-theorem-ols-blue/}

The Gauss-Markov theorem states that if you linear regression satisfies the first 6 classical assumption, the Ordinary least squares (OLS) produces unbiased estimates that have the smallest variable of all possible linear estimators.

The Gauss-Markov theorem famously states that OLS is (Best Linear Unbiased Estimator) BLUE.

In this context, \textbf{best} refers to the minimum variance.

\textbf{MULUE:} Minimum Variance Linear Unbiased Estimate

\url{https://link.springer.com/chapter/10.2991/978-94-91216-83-1_13}

\hypertarget{consistency-asymptotic-unbiasedness}{%
\subsection{Consistency, asymptotic unbiasedness}\label{consistency-asymptotic-unbiasedness}}

\textbf{Simple consistency:}

\emph{P.311}

Let \(\{T_n\}\) be a sequence of estimators of \(\tau(\theta)\). These estimators are said to be \textbf{consistent} estimators of \(\tau(\theta)\) if for every \(\varepsilon >0\),

\[lim_{n\rightarrow \infty}P[|T_n-\tau(\theta)|<\varepsilon]=1\]

for every \(\theta \in \Omega\).

In the terminology of Chapter 7, \(T_n\) converges \textbf{stochastically} to \(\tau(\theta)\), \(T_n \xrightarrow{P} \tau(\theta)\) as \(n \rightarrow \infty\). Sometimes this also is referred to as \textbf{simple} consistency.

One interpretation of consistency is that for large sample size the estimator tends to be more concentrated about \(\tau(\theta)\), and by making \(n\) sufficiently large \(T_n\) can be made as concentrated as desired.

\textbf{MSE consistency:}

If \(\{ T_n \}\) is a sequence of estimator of \(\tau(\theta)\), then they are called \textbf{mean squared error consistent} if

\[lim_{n\rightarrow \infty} E[T_n - \tau(\theta)]^2=0\]

for every \(\theta \in \Omega\).

\textbf{Asymptotic Unbiased}

A sequence \(\{ T_n \}\) is said to be \textbf{asymptotically unbiased} for \(\tau(\theta)\) if

\[lim_{n\rightarrow \infty} E(T_n)=\tau(\theta)\]

for every \(\theta \in \Omega\).

\textbf{Example:}

\emph{P.313}

For a sample from \(X_i \sim EXP(\theta)\), we know that \(T_n=1/ \bar{X}\) is an MLE estimator for \(\tau(\theta)=1/\theta\). Howwever, \(T_n\) is not a unbiased estimator for \(\tau(\theta)\), as

\[E(T_n)=\frac{n}{n-1}\cdot \frac{1}{\theta}\]

We also know that

\[Var(T_n)=\frac{(\frac{n}{n-1})^2}{(n-2)\theta^2}\]

Thus, while \(T_n\) is not unbiased, it is asymptotically unbiased and MSE consistent for \(\tau(\theta)=\frac{1}{\theta}\).

\textbf{Note that}, MSE consistency is a stronger property than simple consistency. Thus, if a sequenc \(\{T_n\}\) is mean squared error consistent, it is also simply consistent.

\hypertarget{efficiency}{%
\subsection{Efficiency}\label{efficiency}}

\emph{P.308}

The relative efficiency of an \textbf{unbiased} estimator \(T\) of \(\tau(\theta)\) to another \textbf{unbiased} estimator \(T^*\) of \(\tau(\theta)\) is given by

\[re(T, T^*)=\frac{Var(T^*)}{Var(T)}\]

An unbiased estimator \(T^*\) of \(\tau(\theta)\) is said to be efficient if \(re(T, T^*) \leq 1\) for all unbiased estimators \(T\) of \(\tau(\theta)\), and all \(\theta \in \Omega\). The efficiency of an unbiased estimator \(T\) of \(\tau(\theta)\) is given by

\[e(T)=re(T, T^*)\]

if \(T^*\) is an efficient estimator of \(\tau(\theta)\).

Thus, \textbf{an effecient estimator is just a UMVUE.}

\textbf{Example:}

\emph{P.233 Example 7.2.2}

\emph{P.303 Example 9.3.2}

\emph{P.309 Example 9.3.7}

Let \(X_1,X_2,...,X_n\) sample from \(X_i \sim EXP(\theta)\). We know that

\[X_{1:n}=EXP(\theta/n)\]

Thus,

\[E(nX_{1:n})=nE(X_{1:n})=n\frac{\theta}{n}=\theta\]
Thus,

\[nX_{1:n}\]
is the unbiased estimator for \(\theta\).

Thus,

\[re(T,T^*)=\frac{Var(T^*)}{Var(T)}=\frac{Var(\bar{X})}{Var(nX_{1:n})}=\frac{\theta^2/n}{n^2Var(X_{1:n})}=\frac{\theta^2/n}{n^2(\theta/n)^2}=\frac{\theta^2/n}{\theta^2}=\frac{1}{n}\]
Thus, \(T^*=\bar{X}\) is a more efficient estimator for \(\theta\) than \(T=nX_{1:n}\).

\hypertarget{asymptotic-efficiency}{%
\subsection{Asymptotic efficiency}\label{asymptotic-efficiency}}

Let \(\{T_n\}\) and \(\{T_n^*\}\) be the two asymptotically unbiased sequences of estimators for \(\tau(\theta)\). The \textbf{asymptotic relative efficiency} of \(T_n\)relative to \(T_n^*\) is given by

\[are(T_n,T_n^*)=lim_{n \rightarrow \infty} \frac{Var(T_n^*)}{Var(T_n)}\]
The sequence \(\{T_n^*\}\) is said to asymptotically efficient if \(are\{T_n, T_n^*\} \leq 1\) for all other asymptotically unbiased sequences \(\{T_n\}\), and all \(\theta \in \Omega\).

\hypertarget{asymptotic-properties-of-mles}{%
\subsection{Asymptotic properties of MLEs}\label{asymptotic-properties-of-mles}}

\emph{P.316}

If certain regularity conditions are satisfied, then the solutions, \(\hat{\theta}\), of the MLE have the following properties:

\begin{enumerate}
\def\labelenumi{(\arabic{enumi})}
\item
  \(\hat{\theta_n}\) exists and is unique.
\item
  \(\hat{\theta_n}\) is a consistent estimator of \(\theta\).
\item
  \(\hat{\theta_n}\) is asymptotically normal with asymptotic mean \(\theta\) and variance
\end{enumerate}

\[\frac{1}{2}E[\frac{\partial}{\partial\theta}ln \; f(X;\theta)]^2\]

\begin{enumerate}
\def\labelenumi{(\arabic{enumi})}
\setcounter{enumi}{3}
\tightlist
\item
  \(\hat{\theta}\) is asymptotically efficient.
\end{enumerate}

Note that the asymptotic efficiency of \(\hat{\theta}\) follows from the fact that the asymptotic variance is the same as the \textbf{CRLB} for unbiased estimators of \(\theta\). Thus, for large \(n\), approximately

\[\hat{\theta_n} \sim N(\theta, CRLB)\]

\textbf{Example}

\emph{P.317}

From Example 9.2.7, we know the MLE of the mean \(\theta\) of an exponential distribution is the sample mean, \(\hat{\theta_n}=\bar{X}\).

We can infer the same asymptotic properties either from the discussion above or from the Central Limit Theorem. That is, \(\hat{\theta_n}\) is asymptotically normal with asymptotic mean \(\theta\) and variance \(\theta^2/n\). From example 9.3.4, we know that \(CRLB=\theta^2/n\).

Thus,

\[\sqrt{n}\frac{\hat{\theta_n}-\theta}{\theta}\sim N(0,1)\]

\hypertarget{sufficient-and-completeness}{%
\section{Sufficient and completeness}\label{sufficient-and-completeness}}

\hypertarget{sufficiency-and-minimal-sufficiency}{%
\subsection{Sufficiency and minimal sufficiency}\label{sufficiency-and-minimal-sufficiency}}

\emph{P.335}

\textbf{Sufficient statistic:}

A statistic \(S\) will be consiered a ``sufficient'' statistic for a parameter \(\theta\) if the conditional distribution of any other statistic \(T\) given the value of \(S\) does not involve \(\theta\).

\textbf{Jointly sufficient statistics:}

Let \(X=(X_1,...,X_n)\) have joint pdf \(f(x,\theta)\), and let \(S=(S_1,...,S_k)\) be a k-dimensional statistic.

Then, \(S_1,...,S_k\) is a set of \textbf{jointly sufficient statistics} for \(\theta\) if for any other vector of statistics, \(T\), the conditional pdf of \(T\) given \(S=s\), denoted by \(f_{T|s}(t)\), does not depend on \(\theta\).

In the one-dimension case, we simply say that \(S\) is a sufficient statistic for \(\theta\).

If \(k\) unknown parameters are present in the model, then quite often there will exist a set of \(k\) sufficient statistics. In some cases, the number of sufficient statistics will exceed the number of parameters.

\textbf{Minimal sufficient:}

A set of statistics is called a \textbf{minimal sufficient} set if the members of the set are jointly sufficient for the parameters and if they are a function of every other set of jointly sufficient statistics.

\textbf{In other words, once the value of a sufficient statistic is known, the observed value of any other statistic does not contain any further inforamtion about the parameter.}

\textbf{Example:}

\emph{P.339}

Assume a random sample from an exponential distribution, \(X_i \sim EXP(\theta)\). It follows that

\[f(x_1,...,x_n; \theta)=\frac{1}{\theta^n} e^{-\frac{\sum X_i}{\theta}}\]
which suggests checking the stastic \(S=\sum X_i\). We know that \(S \sim GAM(\theta,n)\), thus

\[f_S(s; \theta)=\frac{1}{\theta^n \Gamma(n)}s^{n-1}e^{-\frac{s}{n}}\]

If \(s=\sum x_i\), then,

\[\frac{f(x_1,...,x_n; \theta)}{f_S(s;\theta)}=\frac{\Gamma(n)}{s^{n-1}}\]

which is free of \(\theta\), and thus by definition S is sufficient for \(\theta\).

\hypertarget{neyman-factorization-theorem-minimal-sufficiency-of-mles}{%
\subsection{Neyman factorization theorem, minimal sufficiency of MLEs}\label{neyman-factorization-theorem-minimal-sufficiency-of-mles}}

\textbf{Factorization criterion:}

If \(X_1,...,X_n\) have joint pdf \(f(x_1,...,x_n; \theta)\), and if \(S=(S_1,...,S_n)\), then \(S_1,...,S_k\) are joinly sufficient for \(\theta\) if and only if

\[f(x_1,...x_n; \theta)=g(s;\theta)h(x_1,...,x_n)\]
where \(g(s;\theta)\) does not depend on \(x_1,...,x_n\), except through \(s\), and \(h(x_1,...,x_n)\) does not involve \(\theta\).

\textbf{Example 1:}

\emph{P.340}

\(X_i \sim Bin(1,\theta)\). We can use factorization criterion to check its sufficient statistic.

\[f(x_1,...,x_n;\theta)=\theta^{\sum x_i}(1-\theta)^{n-\sum x_i}=\theta^s(1-\theta)^{n-s}=g(s;\theta)h(x_1,...,x_n)\]

where \(s=\sum X_i\) and \(h(x_1,...x_n)=1\). Thus, \(s\) is sufficient for \(\theta\).

\textbf{Example 2:}

\textbf{It is important to specify the regions of zero probability. The following shows that care must be exercised in this matter.}

\emph{P.340}

\(X_i \sim UNIF(0,\theta)\), where \(\theta\) is unknown. We get the joint \(pdf\) of \(X_1,...,X_n\) is

\[f(x_1,...x_n; \theta)=\frac{1}{\theta^n}\]
where,

\[0<x_i<\theta\]

It is easier to specify this \(pdf\) in terms of the minimum, \(x_{1:n}\), and maximum, \(x_{n:n}\), of \(x_1,...,x_n\). In particular,

\[0< x_{1:n}  \; \; x_{n:n} <\theta\]

Thus, \(x_{n:n}\) is sufficient for \(\theta\).

\textbf{Example 3:}

\emph{P.341}

Consider a random sample from a normal distribution, \(X_i \sim N(\mu, \sigma^2)\).

We know the \(pdf\) for normal is

\[f=\frac{1}{\sqrt{2\pi \sigma^2 }} e^{-\frac{1}{2\sigma^2}(x-\mu)^2}\]

Thus, the joint \(pdf\) is as follows.

\[\begin{aligned} f(x_1,...,x_n;\mu,\sigma^2) &=\frac{1}{(2\pi\sigma^2)^{\frac{n}{2}}}e^{-\frac{1}{2\sigma^2}\sum (x_i-\mu)^2} \\ &=\frac{1}{(2\pi\sigma^2)^{\frac{n}{2}}}e^{-\frac{1}{2\sigma^2}\sum (x_i^2+\mu^2-2x_i\mu)} \\ &=\frac{1}{(2\pi\sigma^2)^{\frac{n}{2}}}e^{-\frac{1}{2\sigma^2}(\sum x_i^2+n\mu^2-2\mu\sum x_i)} \end{aligned}\]

Thus, \(S_1=\sum X_i\) and \(S_2=\sum X_i^2\) are jointly sufficient for \(\theta={\mu, \sigma^2}\).

\textbf{Note that,}

\emph{P.341}

based on \emph{P.298} , Example 9.2.10, ML estimation results in

\[\hat{\mu}=\bar{x}\]
\[\hat{\sigma^2}=\frac{\sum(x_i-\bar{x})^2}{n}\]

Further, note that

\[\hat{\mu}=\bar{x}=\frac{S_1}{n}\]

\[\begin{aligned} \hat{\sigma^2}&=\frac{\sum(x_i-\bar{x})^2}{n}=\frac{\sum (x_i^2+\bar{x}^2-2x_i\bar{x})}{n} \\ &=\frac{\sum x_i^2+n\bar{x}^2-2\bar{x} \sum x_i}{n} \\ &=\frac{\sum x_i^2+n\bar{x}^2-2n\bar{x}^2}{n} \\&=\frac{\sum x_i^2-n\bar{x}^2}{n} \\&=\frac{\sum x_i^2}{n}-\bar{x}^2 \\ &=\frac{\sum x_i^2}{n}- (\frac{\sum x_i}{n})^2 \\ &=\frac{S_2}{n}-(\frac{S_1}{n})^2 \end{aligned}\]

Thus, we can see that \(\hat{\mu}\) and \(\hat{\sigma^2}\) correspond to a one-to-one stransformation of \(S_1\) and \(S_2\), thus \(\hat{\mu}\) and \(\hat{\sigma^2}\) also are jontly sufficient for \(\mu\) and \(\sigma^2\).

\hypertarget{rao-blackwell-theorem}{%
\subsection{Rao-Blackwell theorem}\label{rao-blackwell-theorem}}

Let \(X_1,...,X_n\) have joint \(pdf \; f(x_1,...,x_n; \theta)\), and let \(S=(S_1,...,S_k)\) be a vector of jointly sufficient statistics for \(\theta\). If \(T\) is any unbiased estimator of \(\tau(\theta)\), and if \(T^*=E(T|S)\), then

\begin{enumerate}
\def\labelenumi{(\arabic{enumi})}
\item
  \(T^*\) is an unbiased estimator of \(\tau(\theta)\),
\item
  \(T^*\) is a function of \(S\), and
\item
  \(Var(T^*) \leq Var(T)\) for every \(\theta\), and \(Var(T^*) < Var(T)\) for some \(\theta\) unless \(T^*=T\) with probability 1.
\end{enumerate}

\textbf{Discussion:}

\emph{P.345}

"It is clear from the Rao-Blackwell theorem that if we are searching for an unbiased estimator with small variance, we may as well restrict attention to function of sufficient statistics.

If any ubiased estimator exists, then there will be one that is a function of sufficient statistics, namely \(E(T|S)\), which also is unbiased and has variance at least as small or smaller. In particular, we still are interested in knowing how to find a UMVUE for a parameter, and the above theorem narrows our problem down somewhat.

For instance, consider a one-parameter model \(f(x;\theta)\), and assume that a single sufficient statistic, \(S\), exists. We know that we must consider only unbiased functions of \(S\) in searching for a UMVUE. In some cases it may be possible to show that only one function of \(S\) is unbiased, and in that case we would know that it is a UMVUE.

The concept of ``completeness'' is helpful in determinning unique unbiased estimators, and this concept is defined in the next section."

\hypertarget{completeness}{%
\subsection{completeness}\label{completeness}}

\textbf{Completeness:}

\emph{P.345}

A family of density functions \(\{ f_T(t,\theta); \theta \in \Omega\}\), is called \textbf{complete} if \(E[u(T)]=0\) for all \(\theta \in \Omega\) implies \(u(T)=0\) with probability 1 for all \(\theta \in \Omega\).

\emph{P.345}

``This sometimes is expressed by saying that there are no nontrivial unbiased estimators of zero. In particular, it means that two different functions of \(T\) cannot have the same expected value.''

For example, if \(E[u_1(T)]=\tau(\theta)\) and \(E[u_2(T)]=\tau(\theta)\), which implies \(u_1(T)-u_2(T)=0\), or \(u_1(T)=u_2(T)\) with probablity 1, if the family of density fucntions is complete. That is, any unbiased estimator is unique in this case.

We mainly are interested in knowing that the family of density functions of a sufficient statistic is complete, because in that case an unbiased function of the sufficient statistic will be unique, and it must be a UMVUE by the Rao-Blackwell theorem.

\hypertarget{lehmann-scheffe-completeness-theorem}{%
\subsection{Lehmann-Scheffe completeness theorem}\label{lehmann-scheffe-completeness-theorem}}

Let \(X_1,...,X_n\) have joint \(pdf \; f(x_1,...,x_n; \theta)\) and let \(S\) be a vector of jointly complete sufficient statistics for \(\theta\). If \(T^*=t^*(S)\) is a statistic that is unbiased for \(\tau(\theta)\) and a function of \(S\), then \(T^*\) is a UMVUE of \(tau(\theta)\).

\textbf{Example:}

\emph{P.346}

\hypertarget{exponential-class-complete-sufficient-statistics}{%
\subsection{Exponential class, complete sufficient statistics}\label{exponential-class-complete-sufficient-statistics}}

A density fucntion is said to be a member of the \textbf{regular exponential class} if it can be expressed in the form

\[f(x; \theta)=c(\theta)h(x)e^{\sum_{j=1}^k q_j(\theta)t_j(x)}\]
where,

\[x \in A\]
And zero otherwise, where \(\theta=(\theta_1,...,\theta_k)\) is a vector of \(k\) unknown parameters, if the parameter space has the form

\[\Omega=\{\theta | a_i \leq \theta_i \leq b_i, i=1,...k\}\]

(note that \(a_i=-\infty\) and \(b_i=\infty\) are permissible values), and if it satisfies regularity conditions 1, 2, and 3a or 3b given by:

\begin{enumerate}
\def\labelenumi{(\arabic{enumi})}
\item
  The set \(A=\{x:f(x; \theta)>0\}\) does not depend on \(\theta\).
\item
  The functions \(q_j(\theta)\) are nontrivial, functionally independent, continuous fucntion of the \(\theta_i\).
\end{enumerate}

3a. For a continuous random variable, the derivatives \(t_k^{'}(x)\) are linearly independent continous functions of \(x\) over \(A\).

3b. For a discrete random variable, the \(t_k(x)\) are nontrivial functions of \(x\) on \(A\), and none is a linear function of the others.

\textbf{Example}

\emph{P.348}

Consider Bernoulli distribution \(X \sim Bin(1,p)\). It follows that

\[\begin{aligned} f(x; p) &=p^x(1-p)^{1-x} \\ &=P^x(1-p)(1-p)^{-x} \\ &=(1-p)(1-p)^{-x}P^x \\&=(1-p)e^{ln(1-p)^{-x}P^x} \\ &=(1-p)e^{xln(\frac{p}{1-p})} \end{aligned}\]

Compared to the definition of \textbf{Exponential Class} defined above, we can get the following.
\[c(\theta)=(1-p)\]
\[h(x)=1\]
\[q_1(\theta)=ln(\frac{p}{1-p})\]
\[t_1(x)=x\]

\textbf{Theorem 10.4.2}

\emph{P.348}

If \(X_1,...,X_n\) is a random sample from a member of the regular exponential class \(REC(q_1,...,q_k)\), then the statistics

\[S_1=\sum_{i=1}^n t_1(X_i),...,S_k=\sum_{i=1}^n t_k(X_i)\]

are a minimal set of complete sufficient statistics for \(\theta_1,...\theta_k\).

\textbf{Example 1:}

\emph{P.348}

Again, consider Bernoulli distribution \(X \sim Bin(1,p)\). For a random sample of size \(n\), \(t(x_i)=x_i\) and thus based on \textbf{Theorem 10.4.2 (see above)} \(S=\sum_{i=1}^n X_i\) is a complete sufficient statistic for \(p\).

\textbf{How about we want to find UMVUE for \(Var(X)=p(1-p)\)?}

We might try \(\bar{X}(1-\bar{X})\).

\[\begin{aligned} E[\bar{X}(1-\bar{X})] &=E(\bar{X})-E(\bar{X}^2) \\ &=p-(p^2+var(\bar{X})) \\ &=p-p^2-\frac{p(1-p)}{n} \\ &=p(1-p)(1-\frac{1}{n}) \end{aligned}\]

Thus,

\[E[\frac{1}{1-\frac{1}{n}}\bar{X}(1-\bar{X})]=p(1-p)\]

Thus, \(\frac{1}{1-\frac{1}{n}}\bar{X}(1-\bar{X})\) is the UMVUE of the \(p(1-p)\).

but \textbf{why?}

\textbf{Example 2:}

\emph{P.349}

If \(X \sim N(\mu,\sigma^2)\), then

\[\begin{aligned} f(x;\mu,\sigma)&=\frac{1}{\sqrt{2\pi \sigma^2}}e^{-\frac{(x-\mu)^2}{2\sigma^2}} \\ &=\frac{1}{\sqrt{2\pi \sigma^2}}e^{-\frac{1}{2\sigma^2}(x^2+\mu^2-2x\mu)} \\ &=\frac{1}{\sqrt{2\pi \sigma^2}}e^{-\frac{x^2}{2\sigma^2}-\frac{\mu^2}{2\sigma^2}+\frac{x\mu}{\sigma^2}} \end{aligned}\]

Thus, \(S_1=\sum X_i^2\) and \(S_2=\sum X_i\) are jointly complete and sufficient statistics of \(\mu\) and \(\sigma^2\). \textbf{Refer to the normal example in the section of ``Neyman factorization theorem, minimal sufficiency of MLEs''}

\textbf{Theorem 10.4.3}

\emph{P.349}

If a CRLB estimator \(T\) exists for \(\tau(\theta)\), then a single sufficient statistic exists, and \(T\) is a function of the sufficient statistic. Conversely, if a single sufficient statistic exists and teh CRLB exists, then a CRLB estimator exists for some \(\tau(\theta)\).

\hypertarget{section-2}{%
\chapter{530\_533}\label{section-2}}

\url{https://www.ssc.wisc.edu/sscc/pubs/RegressionDiagnostics.html}

\url{http://www.sthda.com/english/articles/39-regression-model-diagnostics/161-linear-regression-assumptions-and-diagnostics-in-r-essentials/}

\hypertarget{definition-of-the-general-linear-model}{%
\section{Definition of the general linear model}\label{definition-of-the-general-linear-model}}

\[Y=X\beta+\varepsilon\]

\[\begin{bmatrix}
Y_1 \\
Y_2  \\
...\\
Y_n \end{bmatrix}=\begin{bmatrix}
1 & x_{11} & x_{12} & x_{13} & ... & x_{1m}\\
1 & x_{21} & x_{22} & x_{23} & ... & x_{2m} \\
...\\
1 & x_{n1} & x_{n2} & x_{n3} & ... & x_{nm}
\end{bmatrix} \begin{bmatrix}
\beta_0 \\
\beta_1  \\
...\\
\beta_m \end{bmatrix}+\begin{bmatrix}
\varepsilon_1 \\ \varepsilon_2 \\
...\\
\varepsilon_n  \end{bmatrix}\]

Where,

\(Y\): Response vector

\(X\): Design matrix

\(\beta\): parameter vector

\(\varepsilon\): error vector

If \(\varepsilon\) follows a mutivariate normal distribution then we will be under the General Linear Model (GLM) framework.

\[\varepsilon \sim N(0, \sigma^2I_{x \times n})\]

If \(X\) is continuous we have regression.

If \(X\) is categorical we have ANOVA.

If \(X\) is a mix of both, we have ANCOVA.

\hypertarget{simple-linear-regression}{%
\section{Simple Linear Regression}\label{simple-linear-regression}}

Simple linear regression is a linear regression model with a single explanatory variable. In addition, we typically assume that this is under the GLM framework and thus we also assume that the residuals follow normal distribution.

\hypertarget{least-squares-and-propoerties-of-the-regression-parameters}{%
\subsection{Least squares and propoerties of the regression parameters}\label{least-squares-and-propoerties-of-the-regression-parameters}}

\hypertarget{basic-idea}{%
\subsubsection{Basic idea}\label{basic-idea}}

\textbf{Of note} The following method can always calculate the vector of \(\beta\), not related to any specific methods.

\[Y_{n \times 1}=X_{n\times m}\beta_{m \times 1}\]

\(\rightarrow\)

\[[X^T]_{m \times n}Y_{n \times 1}=[X^T]_{m \times n}X_{n\times m}\beta_{m \times 1}\]
\(\rightarrow\)

\[[X^TX]^{-1}_{m\times m}[X^TY]_{m \times 1}=\beta_{m \times 1}\]

\(\rightarrow\)

\[\beta_{m \times 1}=[(X^TX)^{-1} \cdot (X^TY)]_{m \times 1}\]

Thus,

\[Var(\hat{\beta})=(X^TX)^{-1}X^T \cdot \sigma^2 \cdot [(X^TX)^{-1}X^T]^T\]

\textbf{Residual is given by \(e_i\)}, which is an estimate of \(\varepsilon_i\).

Properties of the residuals \(e_i\) :

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The mean of resituals should be \(0\).
\item
  The variance of \(e_i\):
\end{enumerate}

\[\begin{aligned} Var(e) &=Var(Y-X\hat{\beta}) \\ &=Var(Y-X(X^TX)^{-1}X^TY) \\ &=Var(I-X(X^TX)^{-1}X^T)Y \\&=(I-X(X^TX)^{-1}X^{T})\sigma^2 \end{aligned}\]
Thus,

\[Var(e) \neq \sigma^2\]

\hypertarget{least-squares}{%
\subsubsection{Least Squares}\label{least-squares}}

Assume the following model:

\[Y=X\beta +\varepsilon\]

When \(\beta\) only has a dimension of \(2 \times 1\), we can write it as follows.

\[Y_i=\beta_0+\beta_1X_i +\varepsilon\]

Thus,

\[Q=\sum_{i=1}^n (Y_i-\beta_0-\beta_1X_i)^2\]
We can calculate the partial derivates as follows.

\[\frac{\partial}{\partial \beta_0} Q \rightarrow \sum_{i=1}^n [Y_i-\beta_0-\beta_1X_i]=0\]

\[\frac{\partial}{\partial \beta_1} Q \rightarrow \sum_{i=1}^n [Y_i-\beta_0-\beta_1X_i]X_i=0\]

\textbf{Combining the two pieces of information, we can get}

\[b_1=\frac{\sum(X_i-\bar{X})(Y_i-\bar{Y})}{\sum(X_i-\bar{X})^2}\]

\[b_0=\frac{1}{n}(\sum Y_i-b_1\sum X_i)=\bar{Y}-b_1\bar{X}\]

\textbf{Properties of Least Squares Estimators (Gauss- Markov theorem):}

\emph{P.18}

Under the conditions of regression model shown above, the least squares estimator \(b_0\) and \(b_1\) are unbiased and have minimum variance among all unbiased linear estimators.

That is,

\[E(b_0)=\beta_0\]

\[E(b_1)=\beta_1\]

\textbf{Point Estimation of Mean Response:}

Given sample estimators \(b_0\) and \(b_1\) in the regression function

\[E\{Y\}=\beta_0+\beta_1X\]
We estimate the regression function as follows:

\[\hat{Y}=b_0+b_1X\]

We call a value of the response variable a response and \(E\{Y\}\) the \emph{mean response}.

\textbf{Propoerties of fitted regression line}

\emph{P.22}

The resitual:

\[e_i=Y_i-\hat{Y_i}\]
The sum of the residuals is zero

\[\sum_{i=1}^n e_i=0\]

\hypertarget{point-estimator-of-sigma2}{%
\subsubsection{\texorpdfstring{Point estimator of \(\sigma^2\)}{Point estimator of \textbackslash sigma\^{}2}}\label{point-estimator-of-sigma2}}

Note that, there are two \(S^2\) below, and they have different formulus, even though the only difference is the degree of freedom and the logic of calculating df is the same across these two cases (i.e., \textbf{Single Population vs.~Regression Model} ).

\textbf{1. Single Pupulation}

\textbf{Sum of squares:}

\emph{P.25}

\[\sum_{i=1}^ne_i^2=\sum_{i=1}^n (Y_i-\bar{Y})^2\]

The sum of squares is then divided by the degrees of freedom associated with it.

\[S^2= \frac{\sum_{i=1}^n (Y_i-\bar{Y})^2}{n-1}\]

\(S^2\) is an unbiased estimator of the variance \(\sigma^2\). The sample variance \(S^2\) is often called a mean square, because a sum of squares has been divided by the appropriate number of degrees of freedom.

\[E(S^2)=\sigma^2\]

\textbf{2. Regression model}

\textbf{Sum of Squares Error (SSE) (or, Sum of Squares Residual): }

\[SSE=\sum_{i=1}^n (Y_i-\hat{Y_i})^2=\sum_{i=1}^n e_i^2\]

\textbf{Mean Square Error (MSE) (or, Mean Square Residual):}

\[S^2=MSE=\frac{SSE}{n-2}=\frac{\sum(Y_i-\hat{Y_i})^2}{n-2}=\frac{\sum e_i^2}{n-2}\]
\(MSE\) is an unbiased estimator of \(\sigma^2\) for regression model.

\[E(MSE=S^2)=\sigma^2\]

\hypertarget{mle}{%
\subsection{MLE}\label{mle}}

\emph{P.30}

Note that the \textbf{Normal Error Regression Model} is as follows.

\[Y_i=\beta_0+\beta_1X_i +\varepsilon\]
(This is a special case of the definition provided earlier, i.e., \(Y=X\beta +\varepsilon\))

For this model, each \(Y_i\) observation is normally distributed with mean \(\beta_0+\beta_1x_i\) and a standard devision \(\sigma\).

Givern \(Y_i\) follows normal distribution, we can use \(pdf\) of normal distributions and MLE to estimate parameters.

\[\begin{aligned} L(\beta_0,\beta_1,\sigma^2) &=\prod_{i=1}^n \frac{1}{(2\pi \sigma^2)^{1/2}}exp[-\frac{1}{2 \sigma^2}(Y_i-\beta_0-\beta_1X_i)^2] \\ &=\frac{1}{(2\pi \sigma^2)^{n/2}}exp[-\frac{1}{2 \sigma^2}\sum_{i=1}^n(Y_i-\beta_0-\beta_1X_i)^2]  \end{aligned}\]
Since the variance \(\sigma^2\)is usually unknown, the likelihood fucntion is a function of three parameters, \(\beta_0\), \(\beta_1\), and \(\sigma^2\).

Thus, we can calculate \(\beta_0\), \(\beta_1\), and \(\sigma^2\) analytically, and the results of \(\beta_0\) and \(\beta_1\) are the same as least squares estimators (see above).

The variance \(\sigma^2\) is as follows.

\[\hat{\sigma}^2=\frac{\sum(Y_i-\hat{Y_i})^2}{n}\]

As noted in the least square estimation, we know that \(\hat{\sigma}^2\) is biased. Thus, we know that:

\[S^2=MSE=\frac{n}{n-2}\hat{\sigma}^2\]

\hypertarget{full-rank-less-than-full-rank}{%
\section{Full rank, less than full rank}\label{full-rank-less-than-full-rank}}

\url{http://www.biostat.jhsph.edu/~iruczins/teaching/140.751/notes/ch7.pdf}

\[Y_{n \times 1}=X_{n\times m}\beta_{m \times 1}\]

If the rank \(r\) of \(X_{n \times m}\) is smaller than \(m\), i.e., \(r<m\), there is not a unique solution \(\hat{\beta}\). We have three ways to find a solution \(\hat{\beta}\) and the orthogonal projection \(\hat{Y}\):

\textbf{1. Reducing the model to the full rank.}

Let \(X_1\) consist of \(r\) linear independent columns from \(X\) and let \(X_2\) consistn of the remaining columns. Then, \(X_2=X_1F\) because the columns of \(X_2\) are linearly dependent on the columns of \(X_1\).

\[X=(X_1, X_2)=(X_1, X_1F)=X_1[I_{r\times r}, F]\]
This is a special case of the factorization \(X=KL\), where rank \((K_{n \times r})=r\) and rank \((L_{r\times p})=r\).

\[E[Y]=x\beta=KL\beta=k\alpha\]
Since \(K\) has full rank, the Least Squares Estimate of \(\alpha\) is \(\hat{\alpha}=(K^T K)^{-1} \cdot K^TY\).

The orthogonal project,

\[\hat{Y}=K\cdot \alpha=K \cdot(K^T K)^{-1} \cdot K^TY=X_1 \cdot(X_1^TX_1)^{-1}\cdot X_1^TY\]

\[\begin{bmatrix}
Y_{11} \\ ... \\ Y_{1n_1} \\
Y_{21}  \\ ... \\ Y_{2n_2} \end{bmatrix}=
\begin{bmatrix}
1 & 1 & 0\\
... & ... & ... \\
1 & 1 & 0 \\
1 & 0 & 1 \\ 
... & ... & ... \\
1 & 0 &1 \end{bmatrix} 
\begin{bmatrix}
\mu \\
\beta_1  \\
\beta_2\\
\end{bmatrix}+\begin{bmatrix}
\varepsilon_{11} \\ ... \\ \varepsilon_{1n_1} \\
\varepsilon_{21}  \\ ... \\ \varepsilon_{2n_2}  \end{bmatrix}\]

Let \(X_1\) consist of the first 2 columns of \(X\), then

\[X=X_1 \begin{bmatrix}
1 & 0 & 1 \\ 0 & 1 & -1 \end{bmatrix}\]

Thus,

\[X_1=K=\begin{bmatrix}
1 & 1 \\
... & ...  \\
1 & 1 \\
1 & 0  \\ 
... & ... \\
1 & 0  \end{bmatrix} \]

\[\hat{\alpha}=(K^T K)^{-1} \cdot K^TY=\begin{bmatrix}
n & n_1 \\
n_1 & n_1 \end{bmatrix}^{-1} \begin{bmatrix}
\sum Y_{1j}+\sum y_{2j} \\
\sum y_{1j} \end{bmatrix} =\begin{bmatrix}
\bar{Y_2}\\ \bar{Y_1}-\bar{Y_2} \end{bmatrix}\]

\[\hat{Y}=X_1 \hat{\alpha}=\begin{bmatrix}
1 & 1 \\
... & ...  \\
1 & 1 \\
1 & 0  \\ 
... & ... \\
1 & 0  \end{bmatrix} \begin{bmatrix}
\bar{Y_2}\\ \bar{Y_1}-\bar{Y_2} \end{bmatrix}=\begin{bmatrix}
\bar{Y_1}  \\
...   \\
\bar{Y_1} \\
\bar{Y_2}   \\ 
... \\
\bar{Y_2} \end{bmatrix}\]

\textbf{2. Find the generalized inverse \((X^TX)^{-1}\). }

As noted above, when \(X^TX\) has a full rank, we can directly calculate the inverse of \(X^TX\). That is,

\[\beta_{m \times 1}=[(X^TX)^{-1} \cdot (X^TY)]_{m \times 1}\]

We can just find \textbf{some columns} within \(X\) that are independent, and then calculate the inverse of it.

This is because if a matrix \(W\) with a rank \(r\) and can be partitioned as follows.

\[W=\begin{bmatrix}
A & B  \\
C & D \end{bmatrix}\]

Assume \(A\) has rank \(r\), then

\[W^{-1}=\begin{bmatrix}
A^{-1} &0  \\
0 & 0 \end{bmatrix}\]

Thus, let \(X=(X_1, X_2)\), where \(X_1\) consists of \(r\) linearly independent columns from \(X\). Then a generalized inverse of \(X^TX\) is

\[[X^TX]^{-1}=\begin{bmatrix}
[X_1^TX_1]^{-1}&0  \\
0 & 0 \end{bmatrix}\]

Thus, all other steps are similar to the full rank case.

\textbf{3. Impose identififiability constraints}

(Not very sure this one.)

\hypertarget{assumptions-checking-assumptions}{%
\section{Assumptions, checking assumptions}\label{assumptions-checking-assumptions}}

\textbf{The following are some of the possible violations of assumptions:}

\hypertarget{regression-function-is-nonlinear}{%
\subsection{Regression function is nonlinear}\label{regression-function-is-nonlinear}}

Plot explanatory and response variables to see whether their relationship is linear, it is not, suggesting that a linear regression function is not appropriate.

\textbf{Stat Methods:}

F-test for lack of fit.

\hypertarget{non-constant-variance}{%
\subsection{Non-constant variance}\label{non-constant-variance}}

Plots of the residuals against the predictor variable (i.e., \(X\)) or against the fitted values (i.e., \(\hat{Y}\)), to study whether the linear model is appropriate and whether the \textbf{variance of the error terms} is constant.

\textbf{Stat Methods:}

\textbf{(1) Modified Levene's test (Brown-Forsythe test):}

To check and see if the variability for \(Y\) for the smaller \(X's\) are different than the vairability of \(Y\) for the larger \(X's\).

Thus, we can break up the data into two groups based \(X's\) values. Then, we test to see if the vairability of these two groups significantly differ.

\textbf{Note that} Modefied Levene's test does not depend on normality of the error terms. That is, this test is robust against serious departures from normality.

\textbf{(2) Breusch-Pagan test:}

Want to see if there is any relationship between \(\sigma_i\) and the \(X_i\)'s. To do this, we can fit a regression of \(log(\sigma_i)\) on \(X_i\)'s:

\[log(\sigma_i)=b_0+b_1X_i\]

\hypertarget{error-terms-not-independent}{%
\subsection{Error terms not independent}\label{error-terms-not-independent}}

We want a random pattern. Any type of pattern indicates time orderred problems indicates that the model is not appropriate.

\textbf{Stat Methods:}

\textbf{Durbin Watson Test} Test for presence of autocorrelation amongst observations.

\hypertarget{possibility-of-outliers}{%
\subsection{Possibility of outliers}\label{possibility-of-outliers}}

Scatter plot the dependent variable and independent variables (each \(X_i\) is plotted seprately.)

\hypertarget{non-normal-distribution-of-error}{%
\subsection{Non normal distribution of error}\label{non-normal-distribution-of-error}}

Use histogram to check whether the resitual follows normal distribution.

\textbf{Stat Methods:}

\emph{P.115}

Correlation between ordered residuals and their expected values under normality.

\emph{P.70 512 note}

You can use Shapiro-Wilk, Kolmogorov-Smirnov, Cramer-von Mises, Anderson-Darling in SAS to assess the normal errors.

\hypertarget{omission-of-some-of-the-important-predictors}{%
\subsection{Omission of some of the important predictors}\label{omission-of-some-of-the-important-predictors}}

Plots should be made betweeen variables omitted from the model and the dependent variable. Such omitted variables may have important effects on the response.

\hypertarget{bootstrapping-used-in-linear-models}{%
\section{Bootstrapping used in linear models}\label{bootstrapping-used-in-linear-models}}

\emph{P.458}

\textbf{Intro}

For standard fitted regression models, methods described earlier chapters are available for evaluating the precision of estimated regression coefficients, fitted values, and predictions of new observations.

However, in many nonstandard situations, such as when nonconstant error variance are estimated by iteratively reweighted least sqaure or when robust regression estimation is used, standard methods for evaluating the precision may not be available or may only approximately applicable when the sample size is large.

Bootstrapping was developed by Efron to provide estimates of the precision of sample estimates for these complex cases.

\textbf{Conceptual}

Suppose that we have fitted a regression model (simple or multiple) by some procedure and get the coefficient \(b_1\). We now wish to evaluate the precision of this esimtate by bootsrap method.

\begin{enumerate}
\def\labelenumi{(\arabic{enumi})}
\item
  In essensce, the bootstrap method call for the selection from the observed sample data of a random sample of size \(n\) with replacement.
\item
  Next, the bootstrap method calculates the estimated regression coefficient from the boostrap sample, using the same fitting procedure as employed for the original fitting. This leads to the first bootstrap estimate \(b_1^*\).
\end{enumerate}

This procedure repeated a large number of times, each time a bootstrap sample of size \(n\) is selected with replacement from the original sample and the estimated coefficient is obtained.

\begin{enumerate}
\def\labelenumi{(\arabic{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  The estimated standard deviation of all the bootstrap estimates \(b_1^*\) denoted by \(S^*\{b_1^*\}\), is an estimate of the variability of the sampling distribution of \(b_1\) and therefore a measure of the prevision of \(b_1\).
\end{enumerate}

\textbf{Some Math}

Bootstrapping sampling for regression can be done in two basic ways.

\begin{enumerate}
\def\labelenumi{(\arabic{enumi})}
\tightlist
\item
  Whne the regression fucntion being fitted is a good model for the data, the error terms have constant variance, and the predictor variables can be regarded as fixed, fixed X sampling is appropriate.
\end{enumerate}

Here, the resitudals \(e_i\) from the original fitting are regarded as the sample data to be sampled with replacement. After bootstrap sample of the resituals of size n have beeb obtained, denoted by \(e_1^*, ..., e_n^*\). The bootstrap sample residuals are added to the fitted values from the original fitting to obtain nuew bootstrap Y values, denoted by \(Y_1^*,...,Y_n^*\):

\[Y_i^*=\hat{Y_i}+e_i^*\]
These bootstrap \(Y^*\) values are then regressed on the original \(X\) variables by the same procedure used initially to obtain the bootstrap estimate \(b_1^*\).

\begin{enumerate}
\def\labelenumi{(\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  When there is some doubt about the adequacy of the regressio nmodel, or the rror variances are not constant, or the predictor variables can not be regarded as fixed, random X sampling is appropriate.
\end{enumerate}

For simple regression, the pair \(X\) and \(Y\) data in the oringal sample are considered to be the data to be sampled with replacedment. This this second procedure samples cases with replacement \$n
times, yelding a bootstrap sample of \(n\) pairs of (\(X^*,Y^*\)) values. This bootstrap sample is then used for obtaining the bootstrap estimate \(b_1\), as with fixed \(X\) sampling.

\textbf{Bootstrap confidence intervals}

\emph{P.460}

\hypertarget{generalized-linear-models}{%
\section{Generalized linear models}\label{generalized-linear-models}}

\hypertarget{definition-similarities-and-differences-from-general-linear-models}{%
\subsection{Definition, similarities and differences from general linear models}\label{definition-similarities-and-differences-from-general-linear-models}}

Generalized Linear Model (GLiM) loosens this assumption that \(\varepsilon\) follows a mutivariate normal distribution, and allows for a variety of other distributions from the exponential family for the residuals.

Of note, the GLM is a special case of the GLiM in which the distribution of the residuals follow a conditionally normal distribution.

\hypertarget{advantage-and-disadvantages}{%
\subsection{Advantage and disadvantages}\label{advantage-and-disadvantages}}

\hypertarget{logistic-and-poisson-regression}{%
\subsection{logistic and poisson regression}\label{logistic-and-poisson-regression}}

\textbf{Logistic regression}

Logistic regression is a special case of GLiM with binomial distribution on the \(Y's\) and the link function

The basic idea of logistic regression:
\[p(y=1)=\frac{1}{1+e^{-(\beta_0+\beta_1x_1+...+\beta_nx_n)}}=\frac{e^{\beta_0+\beta_1x_1+...+\beta_nx_n}}{1+e^{\beta_0+\beta_1x_1+...+\beta_nx_n}}\]

Thus, \(\beta_0+\beta_1x_1+...+\beta_nx_n\) can be from \(-\infty\) to \(+\infty\), and \(p(y=1)\) will be always within the range of \((0,1)\).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{f<-}\ControlFlowTok{function}\NormalTok{(x)\{}\KeywordTok{exp}\NormalTok{(x)}\OperatorTok{/}\NormalTok{(}\DecValTok{1}\OperatorTok{+}\KeywordTok{exp}\NormalTok{(x))\}}
\NormalTok{data<-}\KeywordTok{seq}\NormalTok{(}\OperatorTok{-}\DecValTok{10}\NormalTok{,}\DecValTok{10}\NormalTok{,}\DecValTok{1}\NormalTok{)}
\KeywordTok{plot}\NormalTok{(data,}\KeywordTok{f}\NormalTok{(data),}\DataTypeTok{type =} \StringTok{"b"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown-demo_files/figure-latex/unnamed-chunk-1-1.pdf}

We can also write the function into another format as follows:
\[log \frac{p(y=1)}{1-p(y=1)}= \beta_0+\beta_1x_1+...+\beta_nx_n\]
Thus, we know that the regression coeficients of \(\beta_i\) actually change the ``log-odds'' of the event. Of course, note that the magnitude of \(\beta_i\) is dependent upon the units of \(x_i\).

\hypertarget{section-3}{%
\chapter{512}\label{section-3}}

\hypertarget{basics}{%
\section{Basics}\label{basics}}

\hypertarget{random-vs.-fixed}{%
\subsection{Random vs.~Fixed}\label{random-vs.-fixed}}

A factor is \textbf{random} if its levels represent a random sample from a population consisting of a large number of possible levels.

A factor is \textbf{fixed} if its levels are selected by a non-random process or if its levels consist of the entire population of possible levels.

\hypertarget{crossed-vs.-nested}{%
\subsection{Crossed vs.~Nested}\label{crossed-vs.-nested}}

A factor, A, is said to be \textbf{crossed} with respect to a second factor, say B, if each level of factor A is exactly the same for each level of factor B, and each level of factor B is exactly the same for each level of factor A.

Otherwise, the factor is said to be \textbf{nested}. A factor, say B, is \textbf{nested} within another factor, say A, if the levels of factor B are \textbf{not} the same across all levels of factor A.

\hypertarget{completely-randomized-designs}{%
\section{Completely randomized designs}\label{completely-randomized-designs}}

\textbf{Completely random design (CRD)}:

\textbf{Randomly select 9 farms. Randomly assign 3 farms to Variety 1, 3 farms to Variety 2, and 3 farms to Variety 3. This arrangement might appear as in the following table.}

\begin{figure}
\centering
\includegraphics{CRD.png}
\caption{CRD}
\end{figure}

\textbf{All experimental units} (i.e., 9 farms) are \textbf{randomly assigned} to all treatment (i.e., 3 varieties) and therefore the design is a CRD design. That is, across \textbf{all experimental units}, (i.e., 9 farms) they are assumed to be homogeneous before getting the \textbf{assigned treatments}.

\hypertarget{randomized-complete-block-designs}{%
\section{Randomized complete block designs}\label{randomized-complete-block-designs}}

\textbf{Randomized complete block design (RCBD)}:

Randomly select 3 farms. Each farm is divided into 3 subunits with all three varieties, and all 3 varities are randomly assigned into the 3 subunits.

\begin{figure}
\centering
\includegraphics{RCBD.png}
\caption{RCBD}
\end{figure}

The \(t\) treatments are randomly assigned to the \(t\) subunits within each block. Thus, there are \textbf{t-treatments}, with each to be observed \textbf{b times} (i.e., \(t \times b\) experimental units).

In the table above, \textbf{t-treatments} are the 3 varities, whereas \textbf{b times} are the 3 blocks. Thus, \textbf{3 farms} are the \textbf{3 blocks}.

This is a \textbf{Randomized Complete Block Design}. That is, we have a one-way treatment structure (Variety) in a randomized complete block design structure.

We call the \textbf{farms} blocks or \textbf{blocking factor}. Note that block and treatment (Variety) are crossed.

\hypertarget{row-column-design-latin-square-designs}{%
\section{Row-column design (Latin square designs)}\label{row-column-design-latin-square-designs}}

( \textbf{My own short summary:} Latin Square Designs basically are a double-block design.)

Randomly select \textbf{3 farms} and divide each farm into \textbf{3 subunits} with all three Varieties to be assigned to each farm.

In addition, suppose that these farms have fertility gradients (high, medium and low). The treatments are assigned so that each farm (row) receives all three Varieties, but so does each fertility (column) level.

\begin{figure}
\centering
\includegraphics{LSD.png}
\caption{LSD}
\end{figure}

This is a \textbf{Latin Square Design}. That is, we have blocked both on \textbf{rows (farms)} and \textbf{columns (fertility)} such that each treatment occurs once, and only once, within a row or column (e.g., a block).

\hypertarget{comparing-rcbd-versus-crd}{%
\section{Comparing RCBD versus CRD}\label{comparing-rcbd-versus-crd}}

When is it to use RCBD or CRD more efficient?

If there is ``substantial'' amount of variation in the units of replications (i.e., blocks for RCBD; replicats for CRD), then the block design is more efficient and has higher power than CRD.

In contrast, if the variation among units of replication is small, CRD is more efficient and has more power than RCBD.

\hypertarget{incomplete-block-designs}{%
\section{Incomplete block designs}\label{incomplete-block-designs}}

\emph{512 P. 293}

These designs are similar to the RCBD except that each block (e.g., each farm) contains fewer than \(t\) units and thus, only a portion of the \(t\) treatments are applied to the units within each block. (e.g., not all the farms will get all the varieties of wheat).

\hypertarget{split-plot-designs}{%
\section{Split-plot designs}\label{split-plot-designs}}

( \textbf{My own short summary:} The split-plot design is a bit similar to Latin Square Designs, but not exactly the same.)

Consider a completely randomized design with a one-way treatment structure. In this case, suppose the treatment structure consists of 3 variteis of wheat (\(V_1,V_2,V_2\)), each planted on 4 randomly selected farms.

\begin{figure}
\centering
\includegraphics{RCD2.jpg}
\caption{RCD2}
\end{figure}

The ANOVA table for this experiment would appear as follows. As shown, \textbf{farms} are nested within \textbf{Variety}. As we can see, we do not need to model specifically the \textbf{variety} within each farm.

\textbf{Whole Plot and Treatment Structure}

\begin{figure}
\centering
\includegraphics{RCD2_ANOVA.jpg}
\caption{RCD2\_ANOVA}
\end{figure}

However, now suppose that the researcher is also interested in the effect of two different fertilizers (\(F_1, F_2\)) on yield. The completely randomized design can be modified by \_\_splitting\_\_each farm in half. In this experiment, there are two different sizes of experimental units: the large units, which are the farms and the small units, which are the Farm Halves (i.e., fertility levels).

\textbf{Sub-plot Design and Treatment Structure}

\begin{figure}
\centering
\includegraphics{splitting.jpg}
\caption{splitting}
\end{figure}

\begin{figure}
\centering
\includegraphics{splitting_ANOVA.jpg}
\caption{splitting\_ANOVA}
\end{figure}

\_Split plot vs split block design\_\_

\emph{See 512 P.363}

\hypertarget{chapter-12}{%
\chapter{556 Chapter 12}\label{chapter-12}}

\hypertarget{logit-and-probit}{%
\chapter{Logit and Probit}\label{logit-and-probit}}

\hypertarget{logit}{%
\section{Logit}\label{logit}}

\[f(x)=log(\frac{p(y=1)}{1-p(y=1)})\]
The basic idea of logistic regression:
\[p(y=1)=\frac{1}{1+e^{-(\beta_0+\beta_1x_1+...+\beta_nx_n)}}=\frac{e^{\beta_0+\beta_1x_1+...+\beta_nx_n}}{1+e^{\beta_0+\beta_1x_1+...+\beta_nx_n}}\]
Thus, \(\beta_0+\beta_1x_1+...+\beta_nx_n\) can be from \(-\infty\) to \(+\infty\), and \(p(y=1)\) will be always within the range of \((0,1)\).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{f<-}\ControlFlowTok{function}\NormalTok{(x)\{}\KeywordTok{exp}\NormalTok{(x)}\OperatorTok{/}\NormalTok{(}\DecValTok{1}\OperatorTok{+}\KeywordTok{exp}\NormalTok{(x))\}}
\NormalTok{data<-}\KeywordTok{seq}\NormalTok{(}\OperatorTok{-}\DecValTok{10}\NormalTok{,}\DecValTok{10}\NormalTok{,}\DecValTok{1}\NormalTok{)}
\KeywordTok{plot}\NormalTok{(data,}\KeywordTok{f}\NormalTok{(data),}\DataTypeTok{type =} \StringTok{"b"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown-demo_files/figure-latex/unnamed-chunk-2-1.pdf}

We can also write the function into another format as follows:
\[log \frac{p(y=1)}{1-p(y=1)}= \beta_0+\beta_1x_1+...+\beta_nx_n\]
Thus, we know that the regression coeficients of \(\beta_i\) actually change the ``log-odds'' of the event. Of course, note that the magnitude of \(\beta_i\) is dependent upon the units of \(x_i\).

The following is an example testing whether that home teams are more likely to win in NFL games. The results show that the odd of winning is the same for both home and away teams.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mydata =}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\KeywordTok{url}\NormalTok{(}\StringTok{'https://raw.githubusercontent.com/nfl-football-ops/Big-Data-Bowl/master/Data/games.csv'}\NormalTok{))}
\NormalTok{mydata}\OperatorTok{$}\NormalTok{result_new<-}\KeywordTok{ifelse}\NormalTok{(mydata}\OperatorTok{$}\NormalTok{HomeScore}\OperatorTok{>}\NormalTok{mydata}\OperatorTok{$}\NormalTok{VisitorScore,}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{)}
\KeywordTok{summary}\NormalTok{(mydata}\OperatorTok{$}\NormalTok{result_new)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##  0.0000  0.0000  0.0000  0.4945  1.0000  1.0000
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mylogit1 =}\StringTok{ }\KeywordTok{glm}\NormalTok{(result_new}\OperatorTok{~}\DecValTok{1}\NormalTok{, }\DataTypeTok{family=}\NormalTok{binomial, }\DataTypeTok{data=}\NormalTok{mydata)}
\KeywordTok{summary}\NormalTok{(mylogit1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## glm(formula = result_new ~ 1, family = binomial, data = mydata)
## 
## Deviance Residuals: 
##    Min      1Q  Median      3Q     Max  
## -1.168  -1.168  -1.168   1.187   1.187  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(>|z|)
## (Intercept) -0.02198    0.20967  -0.105    0.917
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 126.14  on 90  degrees of freedom
## Residual deviance: 126.14  on 90  degrees of freedom
## AIC: 128.14
## 
## Number of Fisher Scoring iterations: 3
\end{verbatim}

\hypertarget{probit}{%
\section{Probit}\label{probit}}

As noted above, logit \(f(x)=log(\frac{p(y=1)}{1-p(y=1)})\) provides the resulting range of \((0,1)\). Another way to provide the same rage is through the cdf of normal distribution.The following R code is used to illusrate this process.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data2<-}\KeywordTok{seq}\NormalTok{(}\OperatorTok{-}\DecValTok{5}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{1}\NormalTok{)}
\KeywordTok{plot}\NormalTok{(data2,}\KeywordTok{pnorm}\NormalTok{(data2),}\DataTypeTok{type =} \StringTok{"b"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{bookdown-demo_files/figure-latex/unnamed-chunk-4-1.pdf}
Thus, the cdf of normal distribution can be used to indicate the probability of \(p(y=1)\).

\[\Phi(\beta_0+\beta_1x_1+...+\beta_nx_n )= p(y=1)\]

Similar to logit model, we can also write the inverse function of the cdf to get the function that can be from \(-\infty\) to \(+\infty\).

\[\beta_0+\beta_1x_1+...+\beta_nx_n =\Phi^{-1}(p(y=1))\]

Thus, for example, if \(X\beta\) = -2, based on \(\Phi(\beta_0+\beta_1x_1+...+\beta_nx_n )= p(y=1)\) we can get that the \(p(y=1)=0.023\).

In contrast, if \(X\beta\) = 3, the \(p(y=1)=0.999\).

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{pnorm}\NormalTok{(}\OperatorTok{-}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.02275013
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{pnorm}\NormalTok{(}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.9986501
\end{verbatim}

Let's assume that there is a latent variable called \(Y^*\) such that

\[Y^*=X\beta+\epsilon, \epsilon \sim N(0,\sigma^2)\]
You could think of \(Y^*\) as a kind of ``proxy'' between \(X\beta+\epsilon\) and the observed \(Y (1 or 0)\). Thus, we can get the following. Note that, it does not have to be zero, and can be any constant.

\[
Y^*=\begin{cases} 0 \;\;\: if \;  y_i^* \leq 0 \\ 1 \;\;\: if \;  y_i^* > 0 \end{cases}
\]

Thus,

\[y_i^* > 0 \Rightarrow \beta^{'}X_i + \epsilon_i >0 \Rightarrow \epsilon_i > -\beta^{'}X_i\]

Thus, we can write it as follows. Note that \(\frac{ \epsilon_i}{\sigma} \sim N(0,1)\)

\[p(y=1|x_i)= p(y_i^* >0|x_i)=p(\epsilon_i > -\beta^{'}X_i)= p(\frac{ \epsilon_i}{\sigma}>\frac{-\beta^{'}X_i}{\sigma})=\Phi(\frac{\beta^{'}X_i}{\sigma}) \]
We thus can get:

\[p(y=0|x_i)=1-\Phi(\frac{\beta^{'}X_i}{\sigma})\]

For \(p(y=1|x_i)=\Phi(\frac{\beta^{'}X_i}{\sigma})\), we can not really estimate both \(\beta\) and \(\sigma\) as they are in a ratio. We can assume \(\sigma =1\), then \(\epsilon \sim N(0,1)\).
We know \(y_i\) and \(x_i\) since we observe them. Thus, we can write it as follows.

\[p(y=1|x_i)=\Phi(\beta^{'}X_i)\]

\hypertarget{normal-distribution}{%
\chapter{Normal distribution}\label{normal-distribution}}

\hypertarget{basics-1}{%
\section{Basics}\label{basics-1}}

\(\mu\) and \(\sigma\) determine the center and spread of the distribution.

\begin{figure}
\centering
\includegraphics{Standard_deviation_diagram.PNG}
\caption{Normal}
\end{figure}

The empirical rule holds for all normal distributions:

\begin{enumerate}
\def\labelenumi{(\arabic{enumi})}
\item
  68\% of the area under the curve lies between \((\mu-\sigma,\mu+\sigma)\).
\item
  95\% of the area under the curve lies between \((\mu-2\sigma,\mu+2\sigma)\).
\item
  99.7\% of the area under the curve lies between \((\mu-3\sigma,\mu+3\sigma)\).
\end{enumerate}

\hypertarget{confidence-intervals-for-normal-distributions}{%
\section{Confidence intervals for normal distributions}\label{confidence-intervals-for-normal-distributions}}

\[\bar{X} \pm Z \frac{\sigma}{\sqrt{n}}\]
where,

\(\bar{X}\) is the mean

\(Z\) is the Z value (see the table below)

\(\sigma\) is the standard deviation

\(n\) is the number of observations

(We can see the connection between this formula and information shown in the \emph{Basics} section.)

\[\begin{bmatrix}
Confidence \; Levels & Z \\
80  & 1.282 \\
85 & 1.440 \\
90 & 1.645 \\
95 & 1.960 \\
99 & 2.576 \\
99.5 & 2.807 \\
99.9 & 3.291 \end{bmatrix}\]

\hypertarget{percentile}{%
\section{Percentile}\label{percentile}}

A percentile is a measure used in statistics indicating the value below which a given percentage of observations in a group of observations falls.

For example, the 20th percentile is the value (or score) below which 20\% of the observations may be found.

For normal distribution,

-3 \(\sigma\) is the 0.13th percentile (i.e., \(\frac{100-99.7}{2}=0.15\));

-2 \(\sigma\) is the 2.28th percentile ((i.e., \(\frac{100-95}{2}=2.50\)));

-1\(\sigma\) is the 15.87th percentile (i.e., \(\frac{100-68}{2}=16\));

0 \(\sigma\) is 50th percentile.

+2 \(\sigma\) is the 97.72nd percentile (i.e., \(100-\frac{100-95}{2}=100-2.5=97.50\));

+3 \(\sigma\) is the 99.87th percentile (i.e., \(100-\frac{100-99.70}{2}=100-0.15=99.85\)).

This is related to the 68-95-99.7 rule or the three-sigma rule.

(Note that, it is \emph{related}, not \emph{direct} 68-95-99.7 rule, which is about symmetric situations. See the figure above)

\[\begin{bmatrix}
Percentile & Z \\
90  & 1.282 \\
- & 1.440 \\
95 & 1.645 \\
- & 1.960 \\
- & 2.576 \\
- & 2.807 \\
99.9 & 3.000 \end{bmatrix}\]

\hypertarget{intro}{%
\chapter{MLE}\label{intro}}

\hypertarget{basic-idea-of-mle}{%
\section{Basic idea of MLE}\label{basic-idea-of-mle}}

Suppose that we flip a coin, \(y_i=0\) for tails and \(y_i=1\) for heads. If we get \(p\) heads from \(n\) trials, we can get the proportion of heads is \(p/n\), which is the sample mean. If we do not do any further calculation, this is our best guess.

Suppose that the true proablity is \(\rho\), then we can get:

\[
\mathbf{L}(y_i)=\begin{cases} \rho \;\;\:   y_i = 1 \\ 1-\rho \;\;\:  y_i = 0 \end{cases}
\]
Thus, we can also write it as follows.
\[\mathbf{L}(y_i) = \rho^{y_i}(1-\rho)^{1-y_i}\]

Thus, we can get:

\[\prod \mathbf{L}(y_i|\rho)=\rho^{\sum y_i}(1-\rho)^{\sum(1-y_i)}\]
Further, we can get a log-transformed format.

\[log (\prod \mathbf{L}(y_i|\rho))=\sum y_i log \rho + \sum(1-y_i) log(1-\rho)\]

To maximize the log-function above, we can calculate the derivative with respect to \(\rho\).
\[\frac{\partial log (\prod \mathbf{L}(y_i|\rho)) }{\partial \rho}=\sum y_i \frac{1}{\rho}-\sum(1-y_i) \frac{1}{1-\rho}\]
Set the derivative to zero and solve for \(\rho\), we can get

\[\sum y_i \frac{1}{\rho}-\sum(1-y_i) \frac{1}{1-\rho}=0\]
\[\Rightarrow (1-\rho)\sum y_i - \rho \sum(1-y_i) =0\]
\[\Rightarrow \sum y_i-\rho\sum y_i - n\rho +\rho\sum y_i =0\]
\[\Rightarrow \sum y_i - n\rho  =0\]
\[\Rightarrow \rho  = \frac{\sum y_i}{n}=\frac{p}{n}\]
Thus, we can see that the \(\rho\) maximizing the likelihood function is equal to the sample mean.

\hypertarget{coin-flip-example-probit-and-logit}{%
\section{Coin flip example, probit, and logit}\label{coin-flip-example-probit-and-logit}}

In the example above, we are not really trying to estimate a lot of regression coefficients. What we are doing actually is to calculate the sample mean, or intercept in the regresion sense. What does it mean? Let's use some data to explain it.

Suppose that we flip a coin 20 times and observe 8 heads. We can use the R's glm function to esimate the \(\rho\). If the result is consistent with what we did above, we should observe that the \(cdf\) of the esimate of \(\beta_0\) (i.e., intercept) should be equal to \(8/20=0.4\).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{coins<-}\KeywordTok{c}\NormalTok{(}\KeywordTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DataTypeTok{times=}\DecValTok{8}\NormalTok{),}\KeywordTok{rep}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DataTypeTok{times=}\DecValTok{12}\NormalTok{))}
\KeywordTok{table}\NormalTok{(coins)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## coins
##  0  1 
## 12  8
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{coins<-}\KeywordTok{as.data.frame}\NormalTok{(coins)}
\end{Highlighting}
\end{Shaded}

\hypertarget{probit-1}{%
\subsection{Probit}\label{probit-1}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{probitresults <-}\StringTok{ }\KeywordTok{glm}\NormalTok{(coins }\OperatorTok{~}\StringTok{ }\DecValTok{1}\NormalTok{, }\DataTypeTok{family =} \KeywordTok{binomial}\NormalTok{(}\DataTypeTok{link =} \StringTok{"probit"}\NormalTok{), }\DataTypeTok{data =}\NormalTok{ coins)}
\NormalTok{probitresults}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:  glm(formula = coins ~ 1, family = binomial(link = "probit"), 
##     data = coins)
## 
## Coefficients:
## (Intercept)  
##     -0.2533  
## 
## Degrees of Freedom: 19 Total (i.e. Null);  19 Residual
## Null Deviance:       26.92 
## Residual Deviance: 26.92     AIC: 28.92
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{pnorm}\NormalTok{(probitresults}\OperatorTok{$}\NormalTok{coefficients)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## (Intercept) 
##         0.4
\end{verbatim}

As we can see the intercept is \(-0.2533\), and thus \(\Phi(-0.2533471)=0.4\)

\hypertarget{logit-1}{%
\subsection{Logit}\label{logit-1}}

We can also use logit link to calculate the intercept as well. Recall that

\[p(y=1)=\frac{1}{1+e^{-(\beta_0+\beta_1x_1+...+\beta_nx_n)}}=\frac{e^{\beta_0+\beta_1x_1+...+\beta_nx_n}}{1+e^{\beta_0+\beta_1x_1+...+\beta_nx_n}}\]
Thus,

\[p(y=1)=\frac{e^{\beta_0}}{1+e^{\beta_0}}\]

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{logitresults <-}\StringTok{ }\KeywordTok{glm}\NormalTok{(coins }\OperatorTok{~}\StringTok{ }\DecValTok{1}\NormalTok{, }\DataTypeTok{family =} \KeywordTok{binomial}\NormalTok{(}\DataTypeTok{link =} \StringTok{"logit"}\NormalTok{), }\DataTypeTok{data =}\NormalTok{ coins)}
\NormalTok{logitresults}\OperatorTok{$}\NormalTok{coefficients}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## (Intercept) 
##  -0.4054651
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{exp}\NormalTok{(logitresults}\OperatorTok{$}\NormalTok{coefficients)}\OperatorTok{/}\NormalTok{(}\DecValTok{1}\OperatorTok{+}\KeywordTok{exp}\NormalTok{(logitresults}\OperatorTok{$}\NormalTok{coefficients))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## (Intercept) 
##         0.4
\end{verbatim}

Note that, the defaul link for the binomial in the glm function in logit.

\hypertarget{further-on-logit}{%
\section{Further on logit}\label{further-on-logit}}

The probablity of \(y=1\) is as follows:

\[p=p(y=1)=\frac{1}{1+e^{-(\beta_0+\beta_1x_1+...+\beta_nx_n)}}=\frac{e^{\beta_0+\beta_1x_1+...+\beta_nx_n}}{1+e^{\beta_0+\beta_1x_1+...+\beta_nx_n}}\]

Thus, the likelihood function is as follows:

\[L=\prod p^{y_i}(1-p)^{1-y_i}=\prod (\frac{1}{1+e^{-(\beta_0+\beta_1x_1+...+\beta_nx_n)}})^{y_i}(\frac{1}{1+e^{\beta_0+\beta_1x_1+...+\beta_nx_n}})^{1-y_i}\]

\[=\prod (1+e^{-(\beta_0+\beta_1x_1+...+\beta_nx_n)})^{-y_i}(1+e^{\beta_0+\beta_1x_1+...+\beta_nx_n})^{-(1-y_i)}\]

Thus, the log-likelihood is as follows:
\[logL=\sum (-y_i \cdot log(1+e^{-(\beta_0+\beta_1x_1+...+\beta_nx_n)})-(1-y_i)\cdot log(1+e^{\beta_0+\beta_1x_1+...+\beta_nx_n}))\]

Typically, optimisers minimize a function, so we use negative log-likelihood as minimising that is equivalent to maximising the log-likelihood or the likelihood itself.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#Source of R code: https://www.r-bloggers.com/logistic-regression/}

\NormalTok{mle.logreg =}\StringTok{ }\ControlFlowTok{function}\NormalTok{(fmla, data)}
\NormalTok{\{}
  \CommentTok{# Define the negative log likelihood function}
\NormalTok{  logl <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(theta,x,y)\{}
\NormalTok{    y <-}\StringTok{ }\NormalTok{y}
\NormalTok{    x <-}\StringTok{ }\KeywordTok{as.matrix}\NormalTok{(x)}
\NormalTok{    beta <-}\StringTok{ }\NormalTok{theta[}\DecValTok{1}\OperatorTok{:}\KeywordTok{ncol}\NormalTok{(x)]}
    
    \CommentTok{# Use the log-likelihood of the Bernouilli distribution, where p is}
    \CommentTok{# defined as the logistic transformation of a linear combination}
    \CommentTok{# of predictors, according to logit(p)=(x%*%beta)}
\NormalTok{    loglik <-}\StringTok{ }\KeywordTok{sum}\NormalTok{(}\OperatorTok{-}\NormalTok{y}\OperatorTok{*}\KeywordTok{log}\NormalTok{(}\DecValTok{1} \OperatorTok{+}\StringTok{ }\KeywordTok{exp}\NormalTok{(}\OperatorTok{-}\NormalTok{(x}\OperatorTok{%*%}\NormalTok{beta))) }\OperatorTok{-}\StringTok{ }\NormalTok{(}\DecValTok{1}\OperatorTok{-}\NormalTok{y)}\OperatorTok{*}\KeywordTok{log}\NormalTok{(}\DecValTok{1} \OperatorTok{+}\StringTok{ }\KeywordTok{exp}\NormalTok{(x}\OperatorTok{%*%}\NormalTok{beta)))}
    \KeywordTok{return}\NormalTok{(}\OperatorTok{-}\NormalTok{loglik)}
\NormalTok{  \}}
  
  \CommentTok{# Prepare the data}
\NormalTok{  outcome =}\StringTok{ }\KeywordTok{rownames}\NormalTok{(}\KeywordTok{attr}\NormalTok{(}\KeywordTok{terms}\NormalTok{(fmla),}\StringTok{"factors"}\NormalTok{))[}\DecValTok{1}\NormalTok{]}
\NormalTok{  dfrTmp =}\StringTok{ }\KeywordTok{model.frame}\NormalTok{(data)}
\NormalTok{  x =}\StringTok{ }\KeywordTok{as.matrix}\NormalTok{(}\KeywordTok{model.matrix}\NormalTok{(fmla, }\DataTypeTok{data=}\NormalTok{dfrTmp))}
\NormalTok{  y =}\StringTok{ }\KeywordTok{as.numeric}\NormalTok{(}\KeywordTok{as.matrix}\NormalTok{(data[,}\KeywordTok{match}\NormalTok{(outcome,}\KeywordTok{colnames}\NormalTok{(data))]))}
  
  \CommentTok{# Define initial values for the parameters}
\NormalTok{  theta.start =}\StringTok{ }\KeywordTok{rep}\NormalTok{(}\DecValTok{0}\NormalTok{,(}\KeywordTok{dim}\NormalTok{(x)[}\DecValTok{2}\NormalTok{]))}
  \KeywordTok{names}\NormalTok{(theta.start) =}\StringTok{ }\KeywordTok{colnames}\NormalTok{(x)}
  
  \CommentTok{# Calculate the maximum likelihood}
\NormalTok{  mle =}\StringTok{ }\KeywordTok{optim}\NormalTok{(theta.start,logl,}\DataTypeTok{x=}\NormalTok{x,}\DataTypeTok{y=}\NormalTok{y, }\DataTypeTok{method =} \StringTok{'BFGS'}\NormalTok{, }\DataTypeTok{hessian=}\NormalTok{T)}
\NormalTok{  out =}\StringTok{ }\KeywordTok{list}\NormalTok{(}\DataTypeTok{beta=}\NormalTok{mle}\OperatorTok{$}\NormalTok{par,}\DataTypeTok{vcov=}\KeywordTok{solve}\NormalTok{(mle}\OperatorTok{$}\NormalTok{hessian),}\DataTypeTok{ll=}\DecValTok{2}\OperatorTok{*}\NormalTok{mle}\OperatorTok{$}\NormalTok{value)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mydata =}\StringTok{ }\KeywordTok{read.csv}\NormalTok{(}\KeywordTok{url}\NormalTok{(}\StringTok{'https://stats.idre.ucla.edu/stat/data/binary.csv'}\NormalTok{))}
\NormalTok{mylogit1 =}\StringTok{ }\KeywordTok{glm}\NormalTok{(admit}\OperatorTok{~}\NormalTok{gre}\OperatorTok{+}\NormalTok{gpa}\OperatorTok{+}\KeywordTok{as.factor}\NormalTok{(rank), }\DataTypeTok{family=}\NormalTok{binomial, }\DataTypeTok{data=}\NormalTok{mydata)}

\NormalTok{mydata}\OperatorTok{$}\NormalTok{rank =}\StringTok{ }\KeywordTok{factor}\NormalTok{(mydata}\OperatorTok{$}\NormalTok{rank) }\CommentTok{#Treat rank as a categorical variable}
\NormalTok{fmla =}\StringTok{ }\KeywordTok{as.formula}\NormalTok{(}\StringTok{"admit~gre+gpa+rank"}\NormalTok{) }\CommentTok{#Create model formula}
\NormalTok{mylogit2 =}\StringTok{ }\KeywordTok{mle.logreg}\NormalTok{(fmla, mydata) }\CommentTok{#Estimate coefficients}


 \KeywordTok{print}\NormalTok{(}\KeywordTok{cbind}\NormalTok{(}\KeywordTok{coef}\NormalTok{(mylogit1), mylogit2}\OperatorTok{$}\NormalTok{beta))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                          [,1]         [,2]
## (Intercept)      -3.989979073 -3.772676422
## gre               0.002264426  0.001375522
## gpa               0.804037549  0.898201239
## as.factor(rank)2 -0.675442928 -0.675543009
## as.factor(rank)3 -1.340203916 -1.356554831
## as.factor(rank)4 -1.551463677 -1.563396035
\end{verbatim}

\hypertarget{references}{%
\section{References}\label{references}}

\url{http://www.columbia.edu/~so33/SusDev/Lecture_9.pdf}

\hypertarget{score-gradient-and-jacobian}{%
\chapter{Score, Gradient and Jacobian}\label{score-gradient-and-jacobian}}

\hypertarget{score}{%
\section{Score}\label{score}}

The score is the gradient (the vector of partial derivatives) of \(log L(\theta)\), with respect to an m-dimensional parameter vector \(\theta\).

\[S(\theta) = \frac{\partial\ell}{\partial \theta}\]
Typically, they use \(\nabla\) to denote the partical derivative.

\[\nabla \ell\]

Such differentiation will generate a \(m \times 1\) row vector, which indicates the sensitivity of the likelihood.

Quote from Steffen Lauritzen's slides: ``Generally the solution to this equation must be calculated by iterative methods. One of the most common methods is the Newton--Raphson
method and this is based on successive approximations to the solution, using Taylor's theorem to approximate the equation.''

For instance, using logit link, we can get the first derivative of log likelihood logistic regression as follows. We can not really find \(\beta\) easily to make the equation to be 0.

\[\begin{aligned}
\frac{\partial \ell} {\partial \beta} 
&= \sum_{i=1}^{n}x_i^T[y_i-\frac{e^{\beta^Tx_i}}{1+e^{\beta^Tx_i}}] \\
&=\sum_{i=1}^{n} x_i^T[y_i-\hat{y_i}]
\end{aligned}\]

\hypertarget{fisher-scoring}{%
\section{Fisher scoring}\label{fisher-scoring}}

{[}I will come back to this later.{]}

\url{https://www2.stat.duke.edu/courses/Fall00/sta216/handouts/diagnostics.pdf}

\url{https://stats.stackexchange.com/questions/176351/implement-fisher-scoring-for-linear-regression}

\hypertarget{gradient-and-jacobian}{%
\section{Gradient and Jacobian}\label{gradient-and-jacobian}}

\textbf{Remarks}: This part discusses gradient in a more general sense.

When \(f(x)\) is only in a single dimension space:

\(\mathbb{R}^n \rightarrow \mathbb{R}\)

\[\nabla f(x)=[\frac{\partial f}{\partial x_1},\frac{\partial f}{\partial x_2},...,\frac{\partial f}{\partial x_n}]\]
When \(f(x)\) is only in a m-dimension space (i.e., Jacobian):
\(\mathbb{R}^n \rightarrow \mathbb{R^m}\)

\[Jac(f)=\begin{bmatrix}
\frac{\partial f_1}{\partial x_1} & \frac{\partial f_1}{\partial x_2} & \frac{\partial f_1}{\partial x_3} & ... & \frac{\partial f_1}{\partial x_n}\\
\frac{\partial f_2}{\partial x_1} & \frac{\partial f_2}{\partial x_2} & \frac{\partial f_2}{\partial x_3} & ... & \frac{\partial f_2}{\partial x_n} \\
...\\
\frac{\partial f_m}{\partial x_1} & \frac{\partial f_m}{\partial x_2} & \frac{\partial f_n}{\partial x_3} & ... & \frac{\partial f_m}{\partial x_n}
\end{bmatrix}\]

For instance,

\(\mathbb{R}^n \rightarrow \mathbb{R}\):

\[f(x,y)=x^2+2y\]
\[\nabla f(x,y)=[\frac{\partial f}{\partial x},\frac{\partial f}{\partial y}]=[2x,2]\]
\(\mathbb{R}^n \rightarrow \mathbb{R^m}\)

\[f(x,y)=(x^2+2y,x^3)\]
\[Jac(f)=\begin{bmatrix}
2x & 2\\
2x^2 & 0 
\end{bmatrix}\]

\hypertarget{hessian-and-fisher-information}{%
\section{Hessian and Fisher Information}\label{hessian-and-fisher-information}}

Hessian matrix or Hessian is a square matrix of second-order partial derivatives of a scalar-valued function, or scalar field.

\(\mathbb{R}^n \rightarrow \mathbb{R}\)

\[Hessian=\nabla ^2(f) =\begin{bmatrix}
\frac{\partial^2 f}{\partial x_1^2} & \frac{\partial^2 f}{\partial x_1 \partial x_2} & \frac{\partial^2 f}{\partial x_1 \partial x_3} & ... & \frac{\partial^2 f}{\partial x_1 \partial x_n}\\
\frac{\partial^2 f}{\partial x_2 \partial x_1} & \frac{\partial^2 f}{\partial x_2^2} & \frac{\partial^2 f}{\partial x_2 \partial x_3} & ... & \frac{\partial^2 f}{\partial x_2 \partial x_n} \\
\frac{\partial^2 f}{\partial x_3 \partial x_1} & \frac{\partial^2 f}{\partial x_3 \partial x_2} & \frac{\partial^2 f}{\partial x_3^2} & ... & \frac{\partial^2 f}{\partial x_3 \partial x_n} \\
...\\
\frac{\partial^2 f}{\partial x_n \partial x_1} & \frac{\partial^2 f}{\partial x_n \partial x_2} & \frac{\partial^2 f}{\partial x_n \partial x_3} & ... & \frac{\partial^2 f}{\partial x_n^2}
\end{bmatrix}\]

As a special case, in the context of logit:

Suppose that the log likelihood function is \(\ell (\theta)\). \(\theta\) is a \(m\) demension vector.

\[ \theta = \begin{bmatrix}\theta_1 \\
\theta_2 \\
\theta_3 \\
\theta_4 \\
...\\
\theta_m \\
\end{bmatrix}\]

\[Hessian=\nabla ^2(\ell) =\begin{bmatrix}
\frac{\partial^2 \ell}{\partial \theta_1^2} & \frac{\partial^2 \ell}{\partial \theta_1 \partial \theta_2} & \frac{\partial^2 \ell}{\partial \theta_1 \partial \theta_3} & ... & \frac{\partial^2 \ell}{\partial \theta_1 \partial \theta_m}\\
\frac{\partial^2 \ell}{\partial \theta_2 \partial \theta_1} & \frac{\partial^2 \ell}{\partial \theta_2^2 } & \frac{\partial^2 \ell}{\partial \theta_1 \partial \theta_3} & ... & \frac{\partial^2 \ell}{\partial \theta_1 \partial \theta_m} \\
\frac{\partial^2 \ell}{\partial \theta_3 \partial \theta_1} & \frac{\partial^2 \ell}{\partial \theta_3 \theta_2 } & \frac{\partial^2 \ell}{\partial \theta_3^2} & ... & \frac{\partial^2 \ell}{\partial \theta_3 \partial \theta_m} \\
...\\
\frac{\partial^2 \ell}{\partial \theta_m \partial \theta_1} & \frac{\partial^2 \ell}{\partial \theta_m \theta_2 } & \frac{\partial^2 \ell}{\partial \theta_m \partial \theta_3} & ... & \frac{\partial^2 \ell}{\partial \theta_m \partial \theta_m} 
\end{bmatrix}\]

``In statistics, the observed information, or observed Fisher information, is the negative of the second derivative (the Hessian matrix) of the''log-likelihood" (the logarithm of the likelihood function). It is a sample-based version of the Fisher information." (Direct quote from Wikipedia.)

Thus, the observed information matrix:

\[-Hessian=-\nabla ^2(\ell) \]

Expected (Fisher) information matrix:

\[E[-\nabla ^2(\ell)] \]

\hypertarget{canonical-link-function}{%
\chapter{Canonical link function}\label{canonical-link-function}}

Inspired by a Stack Exchange post, I created the following figure:

\[ \frac{Paramter}{\theta} \longrightarrow \gamma^{'}(\theta) = \mu \longrightarrow \frac{Mean}{\mu} \longrightarrow g(\mu) = \eta \longrightarrow \frac{ Linear predictor}{\eta} \]

For the case of \(n\) time Bernoulli (i.e., Binomial), its canonical link function is logit. Specifically,

\[ \frac{Paramter}{\theta=\beta^Tx_i}  \longrightarrow \gamma^{'}(\theta)= \frac{e^{\beta^Tx_i}}{1+e^{\beta^Tx_i}}\longrightarrow \frac{Mean}{\mu=\frac{e^{\beta^Tx_i}}{1+e^{\beta^Tx_i}}}\longrightarrow g(\mu) = log \frac{\frac{e^{\beta^Tx_i}}{1+e^{\beta^Tx_i}}}{1-\frac{e^{\beta^Tx_i}}{1+e^{\beta^Tx_i}}}\longrightarrow \frac{ Linear predictor}{\eta = \beta^Tx_i}\]
Thus, we can see that,

\[\theta \equiv \eta \]
The link function \(g(\mu)\) relates the linear predictor \(\eta = \beta^Tx_i\) to the mean \(\mu\).

\textbf{Remarks}:

\begin{enumerate}
\def\labelenumi{(\arabic{enumi})}
\item
  Parameter is \(\theta = \beta ^T x_i\) (Not \(\mu\)!).
\item
  \(\mu=p(y=1)=\frac{e^{\beta^Tx_i}}{1+e^{\beta^Tx_i}}\) (Not logit!).
\item
  Link function (i.e., \(g(\mu)\)) = logit = logarithm of odds = log \(\frac{Event - Happened }{Event - Not - Happened}\).
\item
  \(g(\mu) = log \frac{\mu}{1-\mu}=\beta^T x_i\). Thus, link function = linear predictor = log odds!
\item
  Quote from the Stack Exchange post ``Newton Method and Fisher scoring for finding the ML estimator coincide, these links simplify the derivation of the MLE.''
\end{enumerate}

(Recall, we know that \(\mu\) or \(p(y=1)\) is the mean function. Recall that, \(n\) trails of coin flips, and get \(p\) heads. Thus \(\mu = \frac{p}{n}\).)

\hypertarget{ordinary-least-squares-ols}{%
\chapter{Ordinary Least Squares (OLS)}\label{ordinary-least-squares-ols}}

Suppose we have \(n\) observation, and \(m\) variables.

\[\begin{bmatrix}
x_{11} & x_{12} & x_{13} & ... & x_{1m}\\
x_{21} & x_{22} & x_{23} & ... & x_{2m} \\
...\\
x_{n1} & x_{n2} & x_{n3} & ... & x_{nm}
\end{bmatrix}\]

Thus, we can write it as the following \(n\) equations.

\[y_1=\beta_0+\beta_1 x_{11}+\beta_2 x_{12}+...+ \beta_m x_{1m}\]
\[y_2=\beta_0+\beta_1 x_{21}+\beta_2 x_{22}+...+ \beta_m x_{2m}\]
\[y_3=\beta_0+\beta_1 x_{31}+\beta_2 x_{32}+...+ \beta_m x_{3m}\]
\[...\]

\[y_n=\beta_0+\beta_1 x_{n1}+\beta_2 x_{n2}+...+ \beta_m x_{nm}\]

We can combine all the \(n\) equations as the following one:

\[y_i=\beta_0+\beta_1 x_{i1}+\beta_2 x_{i2}+...+ \beta_m x_{im}  (i \in [1,n])\]

We can further rewrite it as a matrix format as follows.

\[y= X \beta\]
Where,

\[y = \begin{bmatrix}y_1 \\
y_2 \\
y_3 \\
y_4 \\
...\\
y_n \\
\end{bmatrix}\]

\[X=\begin{bmatrix}
1 & x_{11} & x_{12} & x_{13} & ... & x_{1m}\\
1 & x_{21} & x_{22} & x_{23} & ... & x_{2m} \\
...\\
1 & x_{n1} & x_{n2} & x_{n3} & ... & x_{nm}
\end{bmatrix}\]

\[\beta = \begin{bmatrix}\beta_0 \\
\beta_1 \\
\beta_2 \\
\beta_3 \\
...\\
\beta_m \\
\end{bmatrix}\]

Since later we need the inverse of \(X\), we need to make it into a square matrix.

\[X^Ty=X^TX \hat{\beta} \Rightarrow \hat{\beta} = (X^TX)^{-1} X^Ty\]

We can use R to implement this calculation. As we can see, there is no need to do any iterations at all, but rather just pure matrix calculation.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{X<-}\KeywordTok{matrix}\NormalTok{(}\KeywordTok{rnorm}\NormalTok{(}\DecValTok{1000}\NormalTok{),}\DataTypeTok{ncol=}\DecValTok{2}\NormalTok{) }\CommentTok{# we define a 2 column matrix, with 500 rows}
\NormalTok{X<-}\KeywordTok{cbind}\NormalTok{(}\DecValTok{1}\NormalTok{,X) }\CommentTok{# add a 1 constant}
\NormalTok{beta_true<-}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{) }\CommentTok{# True regression coefficients}
\NormalTok{beta_true<-}\KeywordTok{as.matrix}\NormalTok{(beta_true)}
\NormalTok{y=X}\OperatorTok{%*%}\NormalTok{beta_true}\OperatorTok{+}\KeywordTok{rnorm}\NormalTok{(}\DecValTok{500}\NormalTok{)}

\NormalTok{transposed_X<-}\KeywordTok{t}\NormalTok{(X)}
\NormalTok{beta_hat<-}\KeywordTok{solve}\NormalTok{(transposed_X}\OperatorTok{%*%}\NormalTok{X)}\OperatorTok{%*%}\NormalTok{transposed_X}\OperatorTok{%*%}\NormalTok{y}
\NormalTok{beta_hat}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##          [,1]
## [1,] 1.953008
## [2,] 1.002497
## [3,] 1.953470
\end{verbatim}

\textbf{Side Notes}
The function of as.matrix will automatically make c(2,1,2) become the dimension of \(3 \times 1\), you do not need to transpose the \(\beta\).

\hypertarget{taylor-series}{%
\section{Taylor series}\label{taylor-series}}

\[\begin{aligned}
f(x)|_{a} &=f(a)+\frac{f^{'}(a)}{1!}(x-a)+\frac{f^{'}(a)}{2!}(x-a)^2+\frac{f^{''}(a)}{3!}(x-a)^{3}+...\\&=\sum_{n=0}^{\infty} \frac{f^{n}(a)}{n!}(x-a)^n 
\end{aligned}\]

For example:

\[\begin{aligned} 
e^x |_{a=0} &= e^a+ \frac{e^a}{1!}(x-a)+\frac{e^a}{2!}(x-a)^2+...+\frac{e^a}{n!}(x-a)^n \\ 
&=  1+ \frac{1}{1!}x+\frac{1}{2!}x^2+...+\frac{1}{n!}x^n
\end{aligned}\]

if \(x=2\)

\(e^2 = 7.389056\)

\(e^2 \approx 1+\frac{1}{1!}x =1+\frac{1}{1!}2=3\)

\(e^2 \approx 1+\frac{1}{1!}x+\frac{1}{2!}x^2 =1+\frac{1}{1!}2 + \frac{1}{2!}2 =5\)
\ldots{}

\(e^2 \approx 1+\frac{1}{1!}x+\frac{1}{2!}x^2 +\frac{1}{3!}x^2+\frac{1}{4!}x^2+\frac{1}{5!}x^2=7.2666...\)

\hypertarget{references-1}{%
\section{References}\label{references-1}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Steffen Lauritzen's slides:
\end{enumerate}

\url{http://www.stats.ox.ac.uk/~steffen/teaching/bs2HT9/scoring.pdf}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  The Stack Exchange post:
\end{enumerate}

\url{https://stats.stackexchange.com/questions/40876/what-is-the-difference-between-a-link-function-and-a-canonical-link-function}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Wilipedia for OLS
\end{enumerate}

\url{https://en.wikipedia.org/wiki/Ordinary_least_squares}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Gradient and Jacobian
\end{enumerate}

\url{https://math.stackexchange.com/questions/1519367/difference-between-gradient-and-jacobian}

\url{https://www.youtube.com/watch?v=3xVMVT-2_t4}

\url{https://math.stackexchange.com/questions/661195/what-is-the-difference-between-the-gradient-and-the-directional-derivative}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Hessian
\end{enumerate}

\url{https://en.wikipedia.org/wiki/Hessian_matrix}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{5}
\tightlist
\item
  Observed information
\end{enumerate}

\url{https://en.wikipedia.org/wiki/Observed_information}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{6}
\tightlist
\item
  Fisher information
\end{enumerate}

\url{https://people.missouristate.edu/songfengzheng/Teaching/MTH541/Lecture\%20notes/Fisher_info.pdf}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{7}
\tightlist
\item
  Link function
\end{enumerate}

\url{https://en.wikipedia.org/wiki/Generalized_linear_model\#Link_function}

\url{https://stats.stackexchange.com/questions/40876/what-is-the-difference-between-a-link-function-and-a-canonical-link-function}

\hypertarget{cholesky-decomposition}{%
\chapter{Cholesky decomposition}\label{cholesky-decomposition}}

\hypertarget{example-1}{%
\section{Example 1}\label{example-1}}

Use Cholesky decomposition to generate 1,000 trivariate normal deviates \(X_1, ..., x_{1000}\) with mean \(\mu\) = (−2, 4, 3) and covariance matrix

\[X=\begin{bmatrix}
2 & -1 & 0.5 \\
-1 & 4 & 1 \\
0.5 & 1 & 5 
\end{bmatrix}\]

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Nsim =}\StringTok{ }\DecValTok{10}           
\NormalTok{means =}\StringTok{ }\KeywordTok{c}\NormalTok{(}\OperatorTok{-}\DecValTok{2}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{3}\NormalTok{)              }
\NormalTok{N_columns =}\StringTok{ }\DecValTok{3}               

\CommentTok{# Generating random standard normal distribution numbers }
\NormalTok{Generated_numbers =}\StringTok{ }\KeywordTok{matrix}\NormalTok{(}\KeywordTok{rnorm}\NormalTok{(N_columns }\OperatorTok{*}\StringTok{ }\NormalTok{Nsim), }\DataTypeTok{nrow =}\NormalTok{ N_columns) }

\CommentTok{# The provided covariance matrix}
\NormalTok{cov_matrix =}\StringTok{ }\KeywordTok{rbind}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{-1}\NormalTok{, }\FloatTok{0.5}\NormalTok{), }\KeywordTok{c}\NormalTok{(}\OperatorTok{-}\DecValTok{1}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{1}\NormalTok{), }\KeywordTok{c}\NormalTok{(}\FloatTok{0.5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{5}\NormalTok{))}

\CommentTok{# Cholesky decomposition }
\NormalTok{Cholesky_decom_results =}\StringTok{ }\KeywordTok{chol}\NormalTok{(cov_matrix)    }

\CommentTok{# Data is transformed using the Cholesky decomposition }
\NormalTok{adjusted_data =}\StringTok{ }\KeywordTok{t}\NormalTok{(Generated_numbers) }\OperatorTok{%*%}\StringTok{ }\NormalTok{Cholesky_decom_results       }

\NormalTok{Final_data =}\StringTok{ }\KeywordTok{t}\NormalTok{(}\KeywordTok{t}\NormalTok{(adjusted_data) }\OperatorTok{+}\StringTok{ }\NormalTok{means)}



\CommentTok{# calculating column means}
\KeywordTok{colMeans}\NormalTok{(Final_data)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -2.387850  4.046815  3.471021
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# calculating column variances}
\KeywordTok{apply}\NormalTok{(Final_data,}\DecValTok{2}\NormalTok{,var)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2.769356 3.208465 5.606242
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# calculating covariance matrix}
\KeywordTok{cov}\NormalTok{(Final_data)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##            [,1]       [,2]      [,3]
## [1,]  2.7693563 -0.4216916 2.2915645
## [2,] -0.4216916  3.2084647 0.3428484
## [3,]  2.2915645  0.3428484 5.6062422
\end{verbatim}

\hypertarget{example-2}{%
\section{Example 2}\label{example-2}}

AR(1) Covariance Matrix with Correlatiion Rho and Variance SigmaSq. Note that, there is only one individual or participant in this data simulation.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n =}\StringTok{ }\DecValTok{10}\NormalTok{;}
\NormalTok{SigmaSq =}\StringTok{ }\DecValTok{5}\NormalTok{;}
\NormalTok{Rho =}\StringTok{ }\FloatTok{0.8}\NormalTok{;}

\NormalTok{V =}\StringTok{ }\KeywordTok{matrix}\NormalTok{(}\KeywordTok{rep}\NormalTok{(n}\OperatorTok{*}\NormalTok{n,}\DecValTok{0}\NormalTok{),n,n);}

\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\NormalTok{n)}
\NormalTok{\{}
  \ControlFlowTok{for}\NormalTok{ (j }\ControlFlowTok{in}\NormalTok{ i}\OperatorTok{:}\NormalTok{n)}
\NormalTok{  \{}
\NormalTok{    V[i,j]=SigmaSq}\OperatorTok{*}\NormalTok{Rho}\OperatorTok{^}\NormalTok{(j}\OperatorTok{-}\NormalTok{i)}
\NormalTok{    V[j,i]=V[i,j]}
\NormalTok{  \}}
\NormalTok{\}}

\KeywordTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}
\NormalTok{random_normal<-}\KeywordTok{rnorm}\NormalTok{(n,}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{)}
\CommentTok{#chol(V) %*% random_normal}
\CommentTok{#colSums (chol(V))}
\NormalTok{b2<-}\KeywordTok{t}\NormalTok{(}\KeywordTok{as.matrix}\NormalTok{(random_normal))}\OperatorTok{%*%}\KeywordTok{chol}\NormalTok{(V)}

\NormalTok{pi =}\StringTok{ }\KeywordTok{exp}\NormalTok{(b2)}\OperatorTok{/}\NormalTok{(}\DecValTok{1} \OperatorTok{+}\StringTok{ }\KeywordTok{exp}\NormalTok{(b2));}

\NormalTok{y<-}\KeywordTok{ifelse}\NormalTok{(pi}\OperatorTok{>}\KeywordTok{runif}\NormalTok{(}\DecValTok{1}\NormalTok{),}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{)}

\NormalTok{y}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
## [1,]    1    1    1    1    1    1    1    1    1     1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# The code above basically completes the generating job! }
\CommentTok{# The code below is to check }

\NormalTok{b =}\StringTok{ }\NormalTok{b2[}\DecValTok{2}\OperatorTok{:}\NormalTok{n]}
\NormalTok{c =}\StringTok{ }\NormalTok{b2[}\DecValTok{1}\OperatorTok{:}\NormalTok{(n}\DecValTok{-1}\NormalTok{)]}
\KeywordTok{cor}\NormalTok{(b,c)   }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.8967058
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{sd}\NormalTok{(}\KeywordTok{as.vector}\NormalTok{(b2))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 3.535119
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# note that, you can not use var, as the mean is not zero, but rather it is 2}
\KeywordTok{var}\NormalTok{(}\KeywordTok{as.vector}\NormalTok{(b2))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 12.49707
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#Not sure why the means are not the same ?}
\KeywordTok{mean}\NormalTok{(}\KeywordTok{as.vector}\NormalTok{(b2))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 10.01925
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{mean}\NormalTok{(random_normal)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2.074626
\end{verbatim}

\hypertarget{example-3}{%
\section{Example 3}\label{example-3}}

The following code very similar to the code shown above. However, it had only one observation. To illustrate the situation where there are more than one individual (or, participant), I did the code below.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n =}\DecValTok{25}\NormalTok{;   }\CommentTok{#the number of time points}
\NormalTok{m=}\StringTok{ }\DecValTok{15}\NormalTok{;   }\CommentTok{# the number of participants or individuals, whichever ways you would like to think }
\NormalTok{SigmaSq =}\StringTok{ }\DecValTok{5}\NormalTok{;}
\NormalTok{Rho =}\StringTok{ }\FloatTok{0.8}\NormalTok{;}

\NormalTok{filling_numbers<-}\KeywordTok{rep}\NormalTok{(n}\OperatorTok{*}\NormalTok{n,}\DecValTok{0}\NormalTok{)}
\NormalTok{V =}\StringTok{ }\KeywordTok{matrix}\NormalTok{(filling_numbers,n,n);}

\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\NormalTok{n)}
\NormalTok{\{}
  \ControlFlowTok{for}\NormalTok{ (j }\ControlFlowTok{in}\NormalTok{ i}\OperatorTok{:}\NormalTok{n)}
\NormalTok{  \{}
\NormalTok{    V[i,j]=SigmaSq}\OperatorTok{*}\NormalTok{Rho}\OperatorTok{^}\NormalTok{(j}\OperatorTok{-}\NormalTok{i)}
\NormalTok{    V[j,i]=V[i,j]}
\NormalTok{  \}}
\NormalTok{\}}

\KeywordTok{set.seed}\NormalTok{(}\DecValTok{2345}\NormalTok{)}
\NormalTok{random_normal<-}\KeywordTok{matrix}\NormalTok{(}\KeywordTok{rnorm}\NormalTok{(m}\OperatorTok{*}\NormalTok{n),}\DataTypeTok{nrow =}\NormalTok{ m)}
\CommentTok{#chol(V) %*% random_normal}
\CommentTok{#colSums (chol(V))}
\NormalTok{b2<-random_normal}\OperatorTok{%*%}\KeywordTok{chol}\NormalTok{(V)}

\NormalTok{pi =}\StringTok{ }\KeywordTok{exp}\NormalTok{(b2)}\OperatorTok{/}\NormalTok{(}\DecValTok{1} \OperatorTok{+}\StringTok{ }\KeywordTok{exp}\NormalTok{(b2));}

\NormalTok{random_unfirom<-}\KeywordTok{matrix}\NormalTok{(}\KeywordTok{runif}\NormalTok{(m}\OperatorTok{*}\NormalTok{n),}\DataTypeTok{nrow =}\NormalTok{ m)}

\NormalTok{y<-}\KeywordTok{ifelse}\NormalTok{(pi}\OperatorTok{>}\NormalTok{random_unfirom,}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{)}
\NormalTok{y}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13]
##  [1,]    0    0    0    0    0    0    1    1    1     1     1     0     1
##  [2,]    0    1    1    1    1    1    0    1    0     0     0     0     0
##  [3,]    1    0    0    0    0    1    0    1    0     1     1     0     0
##  [4,]    1    0    0    0    0    0    0    0    1     0     0     0     0
##  [5,]    0    0    0    0    1    0    0    0    0     0     0     0     1
##  [6,]    0    0    1    1    0    0    0    1    0     0     0     0     0
##  [7,]    0    0    0    0    0    1    0    0    1     0     0     0     1
##  [8,]    1    1    1    1    0    0    0    0    0     1     1     0     0
##  [9,]    1    1    1    1    0    1    1    1    0     1     0     0     0
## [10,]    1    0    1    1    1    1    1    1    1     1     0     0     0
## [11,]    1    1    1    1    1    1    1    1    1     0     1     0     0
## [12,]    1    1    1    1    1    1    0    1    1     1     1     1     0
## [13,]    0    1    0    0    0    0    0    0    1     1     1     1     0
## [14,]    1    1    0    1    1    1    1    1    1     0     0     0     0
## [15,]    1    1    0    1    1    1    1    0    0     1     0     0     1
##       [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24]
##  [1,]     1     1     1     1     0     1     0     0     1     0     0
##  [2,]     0     1     1     1     1     1     0     0     0     1     0
##  [3,]     0     1     0     0     1     1     1     1     0     0     1
##  [4,]     1     0     0     0     0     0     1     0     1     0     0
##  [5,]     0     0     1     1     1     0     1     1     1     0     1
##  [6,]     1     1     0     0     1     0     0     1     0     1     1
##  [7,]     0     0     0     0     0     1     0     0     1     0     0
##  [8,]     0     0     0     0     0     0     0     0     0     1     1
##  [9,]     0     1     1     1     0     0     1     0     0     0     0
## [10,]     1     1     1     1     1     1     1     1     1     1     1
## [11,]     0     0     0     1     0     0     0     0     1     1     1
## [12,]     0     0     0     0     1     1     1     0     0     0     1
## [13,]     0     1     0     0     0     1     0     1     1     1     1
## [14,]     0     0     0     0     1     0     1     0     0     0     0
## [15,]     0     0     0     0     0     0     1     0     1     0     0
##       [,25]
##  [1,]     0
##  [2,]     1
##  [3,]     1
##  [4,]     0
##  [5,]     1
##  [6,]     1
##  [7,]     0
##  [8,]     1
##  [9,]     0
## [10,]     1
## [11,]     0
## [12,]     0
## [13,]     1
## [14,]     0
## [15,]     1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# The code above basically completes the generating job! The code below is to check }

\CommentTok{# The following calcuates variance}
\CommentTok{# calculate variance of each column}
\KeywordTok{mean}\NormalTok{(}\KeywordTok{apply}\NormalTok{(b2, }\DecValTok{2}\NormalTok{, var))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 4.330903
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# calculate variance of each row}
\KeywordTok{mean}\NormalTok{(}\KeywordTok{apply}\NormalTok{(b2, }\DecValTok{1}\NormalTok{, var))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 3.568107
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# The whole table}
\KeywordTok{var}\NormalTok{(}\KeywordTok{as.vector}\NormalTok{(b2))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 4.299165
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# The following code calculates the correlation }
\NormalTok{b =}\StringTok{ }\NormalTok{b2[,}\DecValTok{2}\OperatorTok{:}\NormalTok{n]}
\NormalTok{c =}\StringTok{ }\NormalTok{b2[,}\DecValTok{1}\OperatorTok{:}\NormalTok{(n}\DecValTok{-1}\NormalTok{)]}

\NormalTok{collected_cor<-}\KeywordTok{rep}\NormalTok{(}\DecValTok{0}\NormalTok{,m}\DecValTok{-1}\NormalTok{) }\CommentTok{#creating an empty vector to collect correlation. }
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\NormalTok{(m}\DecValTok{-1}\NormalTok{))}
\NormalTok{\{collected_cor[i]<-}\KeywordTok{cor}\NormalTok{(b[i,],c[i,])\}}
\NormalTok{collected_cor}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 0.8473037 0.7065013 0.6376223 0.5481540 0.7851062 0.6576329 0.4844481
##  [8] 0.6950847 0.6731673 0.6409116 0.7966547 0.7184030 0.8001861 0.7913736
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{mean}\NormalTok{(collected_cor)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.6987535
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{mean}\NormalTok{(y)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.456
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{log}\NormalTok{(}\KeywordTok{mean}\NormalTok{(y)}\OperatorTok{/}\NormalTok{(}\DecValTok{1}\OperatorTok{-}\KeywordTok{mean}\NormalTok{(y)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -0.1764564
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# It will always get a value close to zero, since we set the mean to be zero when simulating the data}
\end{Highlighting}
\end{Shaded}

\bibliography{book.bib,packages.bib}


\end{document}
